{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9978b76",
   "metadata": {},
   "source": [
    "# Credit Risk Multi-Agent Demo with Advanced Document Processing\n",
    "\n",
    "This notebook demonstrates the enhanced multi-agent system for credit risk analysis with:\n",
    "- **Tiered Document Processing**: Smart extraction using regex â†’ section vectorization â†’ full RAG\n",
    "- **Revenue Verification**: Compare reported vs extracted financial data\n",
    "- **Anomaly Detection**: Identify inconsistencies in sector codes and turnover\n",
    "- **AI-Powered Suggestions**: Smart recommendations for data corrections\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "### Core Agents\n",
    "1. **Data Ingestion Agent**: Fetches company data from Companies House API\n",
    "2. **Anomaly Detection Agent**: Identifies sector and turnover inconsistencies\n",
    "3. **Sector Classification Agent**: Suggests correct SIC codes\n",
    "4. **Turnover Estimation Agent**: Provides revenue estimates\n",
    "\n",
    "### Document Processing Agents (NEW)\n",
    "5. **Document Download Agent**: Downloads annual accounts from Companies House\n",
    "6. **Smart Financial Extraction Agent**: Three-tier extraction system\n",
    "7. **RAG Document Agent**: Vector-based semantic document analysis\n",
    "\n",
    "### Processing Tiers\n",
    "- **Tier 1**: Fast regex pattern matching (< 5 seconds)\n",
    "- **Tier 2**: Section-specific intelligent extraction (< 20 seconds)\n",
    "- **Tier 3**: Full RAG analysis with vector database (< 60 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c12211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install requests pandas numpy matplotlib seaborn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ðŸ“Š Libraries loaded successfully\")\n",
    "print(f\"ðŸ•’ Notebook started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f752f72",
   "metadata": {},
   "source": [
    "## ðŸ”§ Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a45c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the src directory to Python path\n",
    "project_root = '/Workspace/Repos/credit_risk_demo/src'  # Adjust path for Databricks\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import our agents\n",
    "try:\n",
    "    from agents.orchestrator import MultiAgentOrchestrator\n",
    "    from agents.rag_document_agent import SemanticQuery\n",
    "    from utils.config_manager import config\n",
    "    print(\"âœ… Multi-agent system imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"ðŸ“ Using mock implementation for demonstration\")\n",
    "    \n",
    "    # Mock classes for demonstration\n",
    "    class MockOrchestrator:\n",
    "        def __init__(self):\n",
    "            self.session_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        def run_enhanced_workflow_with_documents(self, input_data):\n",
    "            return self._generate_mock_enhanced_results(input_data)\n",
    "        \n",
    "        def run_complete_workflow(self, input_data):\n",
    "            return self._generate_mock_results(input_data)\n",
    "        \n",
    "        def _generate_mock_enhanced_results(self, input_data):\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"session_id\": self.session_id,\n",
    "                \"data\": {\n",
    "                    \"companies\": self._generate_mock_companies(),\n",
    "                    \"anomalies\": self._generate_mock_anomalies(),\n",
    "                    \"suggestions\": self._generate_mock_suggestions(),\n",
    "                    \"document_processing\": self._generate_mock_document_processing(),\n",
    "                    \"enhanced_analysis\": self._generate_mock_enhanced_analysis()\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        def _generate_mock_results(self, input_data):\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"session_id\": self.session_id,\n",
    "                \"data\": {\n",
    "                    \"companies\": self._generate_mock_companies(),\n",
    "                    \"anomalies\": self._generate_mock_anomalies(),\n",
    "                    \"suggestions\": self._generate_mock_suggestions()\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        def _generate_mock_companies(self):\n",
    "            return [\n",
    "                {\n",
    "                    \"company_number\": \"12345678\",\n",
    "                    \"company_name\": \"Tech Solutions Ltd\",\n",
    "                    \"sic_codes\": [\"62020\"],\n",
    "                    \"turnover\": 850000,\n",
    "                    \"status\": \"active\"\n",
    "                },\n",
    "                {\n",
    "                    \"company_number\": \"87654321\",\n",
    "                    \"company_name\": \"Green Energy Co\",\n",
    "                    \"sic_codes\": [\"35110\"],\n",
    "                    \"turnover\": 1200000,\n",
    "                    \"status\": \"active\"\n",
    "                },\n",
    "                {\n",
    "                    \"company_number\": \"11223344\",\n",
    "                    \"company_name\": \"Retail Fashion Ltd\",\n",
    "                    \"sic_codes\": [\"47710\"],\n",
    "                    \"turnover\": 650000,\n",
    "                    \"status\": \"active\"\n",
    "                }\n",
    "            ]\n",
    "        \n",
    "        def _generate_mock_anomalies(self):\n",
    "            return {\n",
    "                \"sector_anomalies\": [\n",
    "                    {\n",
    "                        \"company_number\": \"12345678\",\n",
    "                        \"company_name\": \"Tech Solutions Ltd\",\n",
    "                        \"anomaly_type\": \"invalid_sic_code\",\n",
    "                        \"confidence\": 0.95\n",
    "                    }\n",
    "                ],\n",
    "                \"turnover_anomalies\": [\n",
    "                    {\n",
    "                        \"company_number\": \"11223344\",\n",
    "                        \"company_name\": \"Retail Fashion Ltd\",\n",
    "                        \"anomaly_type\": \"turnover_sector_mismatch\",\n",
    "                        \"confidence\": 0.85\n",
    "                    }\n",
    "                ],\n",
    "                \"summary\": {\n",
    "                    \"total_anomalies\": 2,\n",
    "                    \"anomaly_rate\": 0.67\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        def _generate_mock_suggestions(self):\n",
    "            return [\n",
    "                {\n",
    "                    \"company_number\": \"12345678\",\n",
    "                    \"suggestion_type\": \"sector_correction\",\n",
    "                    \"suggested_sic_code\": \"62020\",\n",
    "                    \"confidence\": 0.92,\n",
    "                    \"reasoning\": \"Based on company name and business activities\"\n",
    "                },\n",
    "                {\n",
    "                    \"company_number\": \"11223344\",\n",
    "                    \"suggestion_type\": \"turnover_validation\",\n",
    "                    \"suggested_turnover_range\": [600000, 800000],\n",
    "                    \"confidence\": 0.78,\n",
    "                    \"reasoning\": \"Industry benchmarks for retail fashion companies\"\n",
    "                }\n",
    "            ]\n",
    "        \n",
    "        def _generate_mock_document_processing(self):\n",
    "            return {\n",
    "                \"download_summary\": {\n",
    "                    \"total_documents\": 3,\n",
    "                    \"successful_downloads\": 3\n",
    "                },\n",
    "                \"extraction_summary\": {\n",
    "                    \"total_extractions\": 3,\n",
    "                    \"successful_extractions\": 2,\n",
    "                    \"average_confidence\": 0.82\n",
    "                },\n",
    "                \"rag_summary\": {\n",
    "                    \"total_queries\": 2,\n",
    "                    \"successful_queries\": 2\n",
    "                },\n",
    "                \"extraction_results\": [\n",
    "                    {\n",
    "                        \"financial_data\": {\"revenue\": 845000, \"profit_before_tax\": 155000},\n",
    "                        \"extraction_method\": \"regex_pattern\",\n",
    "                        \"confidence\": 0.9,\n",
    "                        \"processing_time\": 2.3\n",
    "                    },\n",
    "                    {\n",
    "                        \"financial_data\": {\"revenue\": 1180000, \"profit_before_tax\": 225000},\n",
    "                        \"extraction_method\": \"section_vectorization\",\n",
    "                        \"confidence\": 0.85,\n",
    "                        \"processing_time\": 8.7\n",
    "                    },\n",
    "                    {\n",
    "                        \"financial_data\": {\"revenue\": 658000, \"profit_before_tax\": 89000},\n",
    "                        \"extraction_method\": \"full_rag\",\n",
    "                        \"confidence\": 0.72,\n",
    "                        \"processing_time\": 45.2\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        \n",
    "        def _generate_mock_enhanced_analysis(self):\n",
    "            return {\n",
    "                \"enhanced_insights\": [\n",
    "                    {\n",
    "                        \"company_name\": \"Tech Solutions Ltd\",\n",
    "                        \"company_number\": \"12345678\",\n",
    "                        \"reported_revenue\": 850000,\n",
    "                        \"extracted_revenue\": 845000,\n",
    "                        \"discrepancy_percentage\": 0.6,\n",
    "                        \"has_discrepancy\": False,\n",
    "                        \"extraction_confidence\": 0.9,\n",
    "                        \"extraction_method\": \"regex_pattern\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"company_name\": \"Green Energy Co\",\n",
    "                        \"company_number\": \"87654321\",\n",
    "                        \"reported_revenue\": 1200000,\n",
    "                        \"extracted_revenue\": 1180000,\n",
    "                        \"discrepancy_percentage\": 1.7,\n",
    "                        \"has_discrepancy\": False,\n",
    "                        \"extraction_confidence\": 0.85,\n",
    "                        \"extraction_method\": \"section_vectorization\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"company_name\": \"Retail Fashion Ltd\",\n",
    "                        \"company_number\": \"11223344\",\n",
    "                        \"reported_revenue\": 650000,\n",
    "                        \"extracted_revenue\": 658000,\n",
    "                        \"discrepancy_percentage\": 1.2,\n",
    "                        \"has_discrepancy\": False,\n",
    "                        \"extraction_confidence\": 0.72,\n",
    "                        \"extraction_method\": \"full_rag\"\n",
    "                    }\n",
    "                ],\n",
    "                \"summary\": {\n",
    "                    \"total_companies_analyzed\": 3,\n",
    "                    \"companies_with_discrepancies\": 0,\n",
    "                    \"average_discrepancy_rate\": 1.2,\n",
    "                    \"high_confidence_extractions\": 2\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    MultiAgentOrchestrator = MockOrchestrator\n",
    "    print(\"ðŸ”„ Using mock implementation for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2780e326",
   "metadata": {},
   "source": [
    "## ðŸš€ Demo 1: Enhanced Workflow with Document Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the orchestrator\n",
    "orchestrator = MultiAgentOrchestrator()\n",
    "\n",
    "print(f\"ðŸ”¬ Multi-Agent Orchestrator initialized\")\n",
    "print(f\"ðŸ“‹ Session ID: {orchestrator.session_id}\")\n",
    "print(f\"ðŸ•’ Started at: {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f508dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define enhanced workflow input with document processing enabled\n",
    "enhanced_input = {\n",
    "    \"company_numbers\": [\"12345678\", \"87654321\", \"11223344\"],\n",
    "    \"enable_document_processing\": True,\n",
    "    \"fallback_enabled\": True,\n",
    "    \"rag_queries\": [\n",
    "        {\n",
    "            \"query_text\": \"What was the company's revenue for the latest financial year?\",\n",
    "            \"query_type\": \"financial_data\",\n",
    "            \"expected_data_type\": \"numeric\"\n",
    "        },\n",
    "        {\n",
    "            \"query_text\": \"What are the main risk factors mentioned in the annual report?\",\n",
    "            \"query_type\": \"risk_factors\",\n",
    "            \"expected_data_type\": \"text\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"ðŸ“‹ Enhanced workflow configuration:\")\n",
    "print(f\"   â€¢ Companies to analyze: {len(enhanced_input['company_numbers'])}\")\n",
    "print(f\"   â€¢ Document processing: {'âœ… Enabled' if enhanced_input['enable_document_processing'] else 'âŒ Disabled'}\")\n",
    "print(f\"   â€¢ Tiered extraction fallback: {'âœ… Enabled' if enhanced_input['fallback_enabled'] else 'âŒ Disabled'}\")\n",
    "print(f\"   â€¢ RAG queries: {len(enhanced_input['rag_queries'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the enhanced workflow\n",
    "print(\"ðŸ”„ Running enhanced workflow with document processing...\")\n",
    "print(\"â±ï¸  This may take a few moments as we process documents\")\n",
    "\n",
    "enhanced_results = orchestrator.run_enhanced_workflow_with_documents(enhanced_input)\n",
    "\n",
    "if enhanced_results[\"success\"]:\n",
    "    print(\"\\nâœ… Enhanced workflow completed successfully!\")\n",
    "    \n",
    "    # Extract key metrics\n",
    "    companies = enhanced_results[\"data\"][\"companies\"]\n",
    "    anomalies = enhanced_results[\"data\"][\"anomalies\"]\n",
    "    document_processing = enhanced_results[\"data\"][\"document_processing\"]\n",
    "    enhanced_analysis = enhanced_results[\"data\"][\"enhanced_analysis\"]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Workflow Summary:\")\n",
    "    print(f\"   â€¢ Companies processed: {len(companies)}\")\n",
    "    print(f\"   â€¢ Anomalies detected: {anomalies['summary']['total_anomalies']}\")\n",
    "    print(f\"   â€¢ Documents processed: {document_processing['download_summary']['total_documents']}\")\n",
    "    print(f\"   â€¢ Successful extractions: {document_processing['extraction_summary']['successful_extractions']}\")\n",
    "    print(f\"   â€¢ Average extraction confidence: {document_processing['extraction_summary']['average_confidence']:.2f}\")\n",
    "    print(f\"   â€¢ Revenue discrepancies found: {enhanced_analysis['summary']['companies_with_discrepancies']}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ Enhanced workflow failed: {enhanced_results.get('error_message', 'Unknown error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa68874",
   "metadata": {},
   "source": [
    "## ðŸ“Š Document Processing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze extraction methods performance\n",
    "if enhanced_results[\"success\"] and \"document_processing\" in enhanced_results[\"data\"]:\n",
    "    extraction_results = enhanced_results[\"data\"][\"document_processing\"][\"extraction_results\"]\n",
    "    \n",
    "    # Create DataFrame for analysis\n",
    "    extraction_data = []\n",
    "    for i, result in enumerate(extraction_results):\n",
    "        extraction_data.append({\n",
    "            \"company_index\": i + 1,\n",
    "            \"extraction_method\": result[\"extraction_method\"],\n",
    "            \"confidence\": result[\"confidence\"],\n",
    "            \"processing_time\": result[\"processing_time\"],\n",
    "            \"revenue_extracted\": result[\"financial_data\"].get(\"revenue\") if result[\"financial_data\"] else None\n",
    "        })\n",
    "    \n",
    "    df_extraction = pd.DataFrame(extraction_data)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Extraction Method Distribution',\n",
    "            'Confidence vs Processing Time',\n",
    "            'Extraction Method Performance',\n",
    "            'Revenue Extraction Results'\n",
    "        ],\n",
    "        specs=[[{\"type\": \"pie\"}, {\"type\": \"scatter\"}],\n",
    "               [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "    \n",
    "    # Method distribution\n",
    "    method_counts = df_extraction['extraction_method'].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=method_counts.index, values=method_counts.values, name=\"Methods\"),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Confidence vs Processing Time\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_extraction['processing_time'],\n",
    "            y=df_extraction['confidence'],\n",
    "            mode='markers+text',\n",
    "            text=df_extraction['extraction_method'],\n",
    "            textposition=\"top center\",\n",
    "            marker=dict(size=10, color=df_extraction['confidence'], colorscale='Viridis'),\n",
    "            name=\"Extraction Performance\"\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Method performance comparison\n",
    "    method_stats = df_extraction.groupby('extraction_method').agg({\n",
    "        'confidence': 'mean',\n",
    "        'processing_time': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=method_stats['extraction_method'],\n",
    "            y=method_stats['confidence'],\n",
    "            name=\"Avg Confidence\",\n",
    "            marker_color='lightblue'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Revenue extraction results\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=[f\"Company {i}\" for i in df_extraction['company_index']],\n",
    "            y=[r/1000 for r in df_extraction['revenue_extracted']],  # Convert to thousands\n",
    "            name=\"Revenue (Â£000s)\",\n",
    "            marker_color='lightgreen'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"Document Processing Performance Analysis\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Processing Time (seconds)\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Confidence Score\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Average Confidence\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Revenue (Â£000s)\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Display summary table\n",
    "    print(\"\\nðŸ“‹ Extraction Method Performance Summary:\")\n",
    "    display(method_stats.round(2))\n",
    "else:\n",
    "    print(\"âŒ No document processing data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069332e5",
   "metadata": {},
   "source": [
    "## ðŸ” Enhanced Revenue Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ef395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze revenue discrepancies between reported and extracted data\n",
    "if enhanced_results[\"success\"] and \"enhanced_analysis\" in enhanced_results[\"data\"]:\n",
    "    enhanced_insights = enhanced_results[\"data\"][\"enhanced_analysis\"][\"enhanced_insights\"]\n",
    "    \n",
    "    # Create DataFrame for analysis\n",
    "    revenue_data = []\n",
    "    for insight in enhanced_insights:\n",
    "        revenue_data.append({\n",
    "            \"company_name\": insight[\"company_name\"],\n",
    "            \"reported_revenue\": insight[\"reported_revenue\"],\n",
    "            \"extracted_revenue\": insight[\"extracted_revenue\"],\n",
    "            \"discrepancy_percentage\": insight[\"discrepancy_percentage\"],\n",
    "            \"has_discrepancy\": insight[\"has_discrepancy\"],\n",
    "            \"extraction_confidence\": insight[\"extraction_confidence\"],\n",
    "            \"extraction_method\": insight[\"extraction_method\"]\n",
    "        })\n",
    "    \n",
    "    df_revenue = pd.DataFrame(revenue_data)\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Reported vs Extracted Revenue',\n",
    "            'Revenue Discrepancy Analysis',\n",
    "            'Extraction Confidence by Method',\n",
    "            'Revenue Accuracy Summary'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Reported vs Extracted Revenue\n",
    "    x_pos = np.arange(len(df_revenue))\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_revenue['company_name'],\n",
    "            y=[r/1000 for r in df_revenue['reported_revenue']],\n",
    "            name='Reported Revenue',\n",
    "            marker_color='lightblue'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_revenue['company_name'],\n",
    "            y=[r/1000 for r in df_revenue['extracted_revenue']],\n",
    "            name='Extracted Revenue',\n",
    "            marker_color='lightcoral'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Discrepancy percentage\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_revenue['company_name'],\n",
    "            y=df_revenue['discrepancy_percentage'],\n",
    "            name='Discrepancy %',\n",
    "            marker_color='orange'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Confidence by method\n",
    "    method_confidence = df_revenue.groupby('extraction_method')['extraction_confidence'].mean().reset_index()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=method_confidence['extraction_method'],\n",
    "            y=method_confidence['extraction_confidence'],\n",
    "            name='Avg Confidence',\n",
    "            marker_color='green'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Accuracy summary (pie chart of discrepancy status)\n",
    "    accuracy_summary = df_revenue['has_discrepancy'].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=['Accurate' if not disc else 'Discrepancy' for disc in accuracy_summary.index],\n",
    "            values=accuracy_summary.values,\n",
    "            name=\"Accuracy\"\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"Enhanced Revenue Analysis: Reported vs Extracted\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Revenue (Â£000s)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Discrepancy %\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Confidence Score\", row=2, col=1)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Display detailed comparison table\n",
    "    print(\"\\nðŸ“‹ Detailed Revenue Comparison:\")\n",
    "    comparison_table = df_revenue[[\n",
    "        'company_name', 'reported_revenue', 'extracted_revenue', \n",
    "        'discrepancy_percentage', 'extraction_confidence', 'extraction_method'\n",
    "    ]].copy()\n",
    "    \n",
    "    comparison_table['reported_revenue'] = comparison_table['reported_revenue'].apply(lambda x: f\"Â£{x:,.0f}\")\n",
    "    comparison_table['extracted_revenue'] = comparison_table['extracted_revenue'].apply(lambda x: f\"Â£{x:,.0f}\")\n",
    "    comparison_table['discrepancy_percentage'] = comparison_table['discrepancy_percentage'].apply(lambda x: f\"{x:.1f}%\")\n",
    "    comparison_table['extraction_confidence'] = comparison_table['extraction_confidence'].apply(lambda x: f\"{x:.2f}\")\n",
    "    \n",
    "    display(comparison_table)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nðŸ“Š Enhanced Analysis Summary:\")\n",
    "    summary = enhanced_results[\"data\"][\"enhanced_analysis\"][\"summary\"]\n",
    "    print(f\"   â€¢ Total companies analyzed: {summary['total_companies_analyzed']}\")\n",
    "    print(f\"   â€¢ Companies with significant discrepancies: {summary['companies_with_discrepancies']}\")\n",
    "    print(f\"   â€¢ Average discrepancy rate: {summary['average_discrepancy_rate']:.1f}%\")\n",
    "    print(f\"   â€¢ High confidence extractions: {summary['high_confidence_extractions']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No enhanced analysis data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78567b4",
   "metadata": {},
   "source": [
    "## ðŸ”„ Demo 2: Tiered Processing Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7879d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the efficiency of tiered processing\n",
    "print(\"ðŸ”¬ Analyzing Tiered Processing Efficiency\")\n",
    "print(\"\\nTiered Processing Strategy:\")\n",
    "print(\"ðŸ“Š Tier 1 (Regex): Fast pattern matching - targets 80%+ confidence in <5 seconds\")\n",
    "print(\"ðŸŽ¯ Tier 2 (Section): Intelligent section analysis - targets 70%+ confidence in <20 seconds\")\n",
    "print(\"ðŸ§  Tier 3 (RAG): Full semantic analysis - comprehensive extraction in <60 seconds\")\n",
    "\n",
    "# Mock data for tiered processing comparison\n",
    "processing_scenarios = [\n",
    "    {\n",
    "        \"scenario\": \"Simple Financial Statement\",\n",
    "        \"tier1_time\": 1.2, \"tier1_confidence\": 0.92, \"tier1_success\": True,\n",
    "        \"tier2_time\": 0, \"tier2_confidence\": 0, \"tier2_success\": False,\n",
    "        \"tier3_time\": 0, \"tier3_confidence\": 0, \"tier3_success\": False,\n",
    "        \"final_method\": \"Tier 1 (Regex)\"\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Complex Annual Report\",\n",
    "        \"tier1_time\": 2.1, \"tier1_confidence\": 0.65, \"tier1_success\": False,\n",
    "        \"tier2_time\": 8.7, \"tier2_confidence\": 0.82, \"tier2_success\": True,\n",
    "        \"tier3_time\": 0, \"tier3_confidence\": 0, \"tier3_success\": False,\n",
    "        \"final_method\": \"Tier 2 (Section)\"\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Unusual Format Document\",\n",
    "        \"tier1_time\": 1.8, \"tier1_confidence\": 0.45, \"tier1_success\": False,\n",
    "        \"tier2_time\": 12.3, \"tier2_confidence\": 0.58, \"tier2_success\": False,\n",
    "        \"tier3_time\": 35.6, \"tier3_confidence\": 0.78, \"tier3_success\": True,\n",
    "        \"final_method\": \"Tier 3 (RAG)\"\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Standard UK Filing\",\n",
    "        \"tier1_time\": 0.9, \"tier1_confidence\": 0.88, \"tier1_success\": True,\n",
    "        \"tier2_time\": 0, \"tier2_confidence\": 0, \"tier2_success\": False,\n",
    "        \"tier3_time\": 0, \"tier3_confidence\": 0, \"tier3_success\": False,\n",
    "        \"final_method\": \"Tier 1 (Regex)\"\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Multi-language Report\",\n",
    "        \"tier1_time\": 2.5, \"tier1_confidence\": 0.52, \"tier1_success\": False,\n",
    "        \"tier2_time\": 15.2, \"tier2_confidence\": 0.69, \"tier2_success\": False,\n",
    "        \"tier3_time\": 48.9, \"tier3_confidence\": 0.84, \"tier3_success\": True,\n",
    "        \"final_method\": \"Tier 3 (RAG)\"\n",
    "    }\n",
    "]\n",
    "\n",
    "df_scenarios = pd.DataFrame(processing_scenarios)\n",
    "\n",
    "# Calculate total processing time and success rates\n",
    "df_scenarios['total_processing_time'] = (\n",
    "    df_scenarios['tier1_time'] + \n",
    "    df_scenarios['tier2_time'] + \n",
    "    df_scenarios['tier3_time']\n",
    ")\n",
    "\n",
    "df_scenarios['final_confidence'] = (\n",
    "    df_scenarios['tier1_confidence'] * df_scenarios['tier1_success'] +\n",
    "    df_scenarios['tier2_confidence'] * df_scenarios['tier2_success'] +\n",
    "    df_scenarios['tier3_confidence'] * df_scenarios['tier3_success']\n",
    ")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[\n",
    "        'Processing Time by Tier',\n",
    "        'Final Method Distribution',\n",
    "        'Confidence vs Processing Time',\n",
    "        'Efficiency Analysis'\n",
    "    ],\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}],\n",
    "           [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    ")\n",
    "\n",
    "# Processing time breakdown\n",
    "for i, scenario in enumerate(df_scenarios['scenario']):\n",
    "    row = df_scenarios.iloc[i]\n",
    "    y_pos = [i] * 3\n",
    "    \n",
    "    if row['tier1_success']:\n",
    "        color = 'green'\n",
    "        time_used = row['tier1_time']\n",
    "    elif row['tier2_success']:\n",
    "        color = 'orange'\n",
    "        time_used = row['tier1_time'] + row['tier2_time']\n",
    "    else:\n",
    "        color = 'red'\n",
    "        time_used = row['total_processing_time']\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=[time_used],\n",
    "            y=[scenario],\n",
    "            orientation='h',\n",
    "            name=f\"{scenario}\",\n",
    "            marker_color=color,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Final method distribution\n",
    "method_counts = df_scenarios['final_method'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=method_counts.index, \n",
    "        values=method_counts.values, \n",
    "        name=\"Methods\"\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Confidence vs Processing Time scatter\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_scenarios['total_processing_time'],\n",
    "        y=df_scenarios['final_confidence'],\n",
    "        mode='markers+text',\n",
    "        text=df_scenarios['final_method'],\n",
    "        textposition=\"top center\",\n",
    "        marker=dict(\n",
    "            size=12, \n",
    "            color=df_scenarios['final_confidence'], \n",
    "            colorscale='RdYlGn',\n",
    "            showscale=True\n",
    "        ),\n",
    "        name=\"Performance\"\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Efficiency analysis (confidence per second)\n",
    "df_scenarios['efficiency'] = df_scenarios['final_confidence'] / df_scenarios['total_processing_time']\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=df_scenarios['scenario'],\n",
    "        y=df_scenarios['efficiency'],\n",
    "        name='Efficiency (Confidence/Second)',\n",
    "        marker_color='purple'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    title_text=\"Tiered Processing Performance Analysis\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Processing Time (seconds)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Processing Time (seconds)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Confidence Score\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Efficiency Score\", row=2, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Display efficiency analysis\n",
    "print(\"\\nðŸ“Š Tiered Processing Efficiency Summary:\")\n",
    "efficiency_summary = df_scenarios[[\n",
    "    'scenario', 'final_method', 'total_processing_time', \n",
    "    'final_confidence', 'efficiency'\n",
    "]] .copy()\n",
    "\n",
    "efficiency_summary['total_processing_time'] = efficiency_summary['total_processing_time'].round(1)\n",
    "efficiency_summary['final_confidence'] = efficiency_summary['final_confidence'].round(3)\n",
    "efficiency_summary['efficiency'] = efficiency_summary['efficiency'].round(4)\n",
    "\n",
    "display(efficiency_summary)\n",
    "\n",
    "# Calculate tier success rates\n",
    "tier1_success_rate = df_scenarios['tier1_success'].mean() * 100\n",
    "tier2_success_rate = df_scenarios['tier2_success'].mean() * 100\n",
    "tier3_success_rate = df_scenarios['tier3_success'].mean() * 100\n",
    "\n",
    "avg_processing_time = df_scenarios['total_processing_time'].mean()\n",
    "avg_confidence = df_scenarios['final_confidence'].mean()\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Tier Success Rates:\")\n",
    "print(f\"   â€¢ Tier 1 (Regex): {tier1_success_rate:.0f}% success rate\")\n",
    "print(f\"   â€¢ Tier 2 (Section): {tier2_success_rate:.0f}% success rate (when Tier 1 fails)\")\n",
    "print(f\"   â€¢ Tier 3 (RAG): {tier3_success_rate:.0f}% success rate (when Tier 1-2 fail)\")\n",
    "print(f\"\\nâš¡ Overall Performance:\")\n",
    "print(f\"   â€¢ Average processing time: {avg_processing_time:.1f} seconds\")\n",
    "print(f\"   â€¢ Average confidence: {avg_confidence:.3f}\")\n",
    "print(f\"   â€¢ System efficiency: {(avg_confidence/avg_processing_time):.4f} confidence/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d73ff6e",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Key Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7bfc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive insights\n",
    "print(\"ðŸ” COMPREHENSIVE ANALYSIS INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nðŸ“Š DOCUMENT PROCESSING PERFORMANCE:\")\n",
    "if enhanced_results[\"success\"] and \"document_processing\" in enhanced_results[\"data\"]:\n",
    "    doc_summary = enhanced_results[\"data\"][\"document_processing\"]\n",
    "    \n",
    "    print(f\"âœ… Successfully processed {doc_summary['download_summary']['total_documents']} documents\")\n",
    "    print(f\"ðŸ“ˆ Achieved {doc_summary['extraction_summary']['average_confidence']:.1%} average extraction confidence\")\n",
    "    print(f\"ðŸŽ¯ {doc_summary['extraction_summary']['successful_extractions']}/{doc_summary['extraction_summary']['total_extractions']} successful extractions\")\n",
    "    \n",
    "    # Method effectiveness\n",
    "    extraction_results = doc_summary.get(\"extraction_results\", [])\n",
    "    method_distribution = {}\n",
    "    for result in extraction_results:\n",
    "        method = result[\"extraction_method\"]\n",
    "        method_distribution[method] = method_distribution.get(method, 0) + 1\n",
    "    \n",
    "    print(f\"\\nðŸ”§ METHOD DISTRIBUTION:\")\n",
    "    for method, count in method_distribution.items():\n",
    "        percentage = (count / len(extraction_results)) * 100\n",
    "        print(f\"   â€¢ {method.replace('_', ' ').title()}: {count} documents ({percentage:.0f}%)\")\n",
    "\n",
    "print(\"\\nðŸš¨ ANOMALY DETECTION RESULTS:\")\n",
    "if enhanced_results[\"success\"]:\n",
    "    anomaly_summary = enhanced_results[\"data\"][\"anomalies\"][\"summary\"]\n",
    "    print(f\"ðŸ” Detected {anomaly_summary['total_anomalies']} anomalies across {len(enhanced_results['data']['companies'])} companies\")\n",
    "    print(f\"ðŸ“Š Anomaly rate: {anomaly_summary['anomaly_rate']:.1%}\")\n",
    "    \n",
    "    sector_anomalies = len(enhanced_results[\"data\"][\"anomalies\"][\"sector_anomalies\"])\n",
    "    turnover_anomalies = len(enhanced_results[\"data\"][\"anomalies\"][\"turnover_anomalies\"])\n",
    "    \n",
    "    print(f\"   â€¢ Sector code anomalies: {sector_anomalies}\")\n",
    "    print(f\"   â€¢ Turnover anomalies: {turnover_anomalies}\")\n",
    "\n",
    "print(\"\\nðŸ’° REVENUE VERIFICATION ANALYSIS:\")\n",
    "if enhanced_results[\"success\"] and \"enhanced_analysis\" in enhanced_results[\"data\"]:\n",
    "    revenue_summary = enhanced_results[\"data\"][\"enhanced_analysis\"][\"summary\"]\n",
    "    \n",
    "    print(f\"ðŸ“‹ Analyzed revenue data for {revenue_summary['total_companies_analyzed']} companies\")\n",
    "    print(f\"âš ï¸  Found significant discrepancies in {revenue_summary['companies_with_discrepancies']} companies\")\n",
    "    print(f\"ðŸ“Š Average discrepancy rate: {revenue_summary['average_discrepancy_rate']:.1f}%\")\n",
    "    print(f\"ðŸŽ¯ High confidence extractions: {revenue_summary['high_confidence_extractions']}/{revenue_summary['total_companies_analyzed']}\")\n",
    "    \n",
    "    # Calculate accuracy rate\n",
    "    accuracy_rate = ((revenue_summary['total_companies_analyzed'] - revenue_summary['companies_with_discrepancies']) / \n",
    "                    revenue_summary['total_companies_analyzed']) * 100\n",
    "    print(f\"âœ… Overall revenue accuracy: {accuracy_rate:.0f}%\")\n",
    "\n",
    "print(\"\\nðŸš€ SYSTEM PERFORMANCE HIGHLIGHTS:\")\n",
    "print(\"âœ¨ INTELLIGENT TIERED PROCESSING:\")\n",
    "print(f\"   â€¢ Tier 1 (Regex): Handles {tier1_success_rate:.0f}% of cases in <5 seconds\")\n",
    "print(f\"   â€¢ Tier 2 (Section): Processes complex documents in <20 seconds\")\n",
    "print(f\"   â€¢ Tier 3 (RAG): Comprehensive analysis for challenging cases\")\n",
    "print(f\"   â€¢ Average processing time: {avg_processing_time:.1f} seconds per document\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ BUSINESS VALUE DELIVERED:\")\n",
    "print(\"ðŸ’¡ AUTOMATED ANOMALY DETECTION:\")\n",
    "print(\"   â€¢ Identifies sector code inconsistencies automatically\")\n",
    "print(\"   â€¢ Flags turnover/sector mismatches for review\")\n",
    "print(\"   â€¢ Provides confidence scores for all detections\")\n",
    "\n",
    "print(\"\\nðŸ“„ ADVANCED DOCUMENT ANALYSIS:\")\n",
    "print(\"   â€¢ Extracts financial data from annual accounts\")\n",
    "print(\"   â€¢ Verifies reported vs actual revenue figures\")\n",
    "print(\"   â€¢ Supports multiple document formats and layouts\")\n",
    "\n",
    "print(\"\\nðŸ¤– AI-POWERED INSIGHTS:\")\n",
    "print(\"   â€¢ Generates smart suggestions for data corrections\")\n",
    "print(\"   â€¢ Provides reasoning for all recommendations\")\n",
    "print(\"   â€¢ Enables human-in-the-loop validation workflow\")\n",
    "\n",
    "print(\"\\nâš¡ SCALABILITY & EFFICIENCY:\")\n",
    "print(\"   â€¢ Tiered processing optimizes speed vs accuracy\")\n",
    "print(\"   â€¢ Vector database enables semantic document search\")\n",
    "print(\"   â€¢ Parallel processing supports high-volume analysis\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ðŸŽ‰ DEMO COMPLETED SUCCESSFULLY!\")\n",
    "print(\"ðŸ“Š The multi-agent system demonstrates enterprise-ready\")\n",
    "print(\"   capabilities for credit risk analysis and document processing.\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384fe22",
   "metadata": {},
   "source": [
    "## ðŸ”§ Configuration and Next Steps\n",
    "\n",
    "### For Production Deployment:\n",
    "\n",
    "1. **API Configuration**:\n",
    "   - Set up Companies House API key in Databricks secrets\n",
    "   - Configure authentication for document downloads\n",
    "\n",
    "2. **Vector Database Setup**:\n",
    "   - Deploy ChromaDB or Pinecone for production RAG\n",
    "   - Configure embedding models (OpenAI, Hugging Face, etc.)\n",
    "\n",
    "3. **Document Processing**:\n",
    "   - Install PDF processing libraries (PyPDF2, pdfplumber)\n",
    "   - Set up document storage (Delta Lake, Azure Blob)\n",
    "\n",
    "4. **Monitoring & Logging**:\n",
    "   - Enable MLflow for experiment tracking\n",
    "   - Set up performance monitoring dashboards\n",
    "\n",
    "5. **Scaling Considerations**:\n",
    "   - Configure cluster auto-scaling\n",
    "   - Implement distributed processing for large datasets\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "\n",
    "- âœ… **Multi-agent coordination** for complex workflows\n",
    "- âœ… **Tiered document processing** (regex â†’ section â†’ RAG)\n",
    "- âœ… **Revenue verification** through document analysis\n",
    "- âœ… **Anomaly detection** with confidence scoring\n",
    "- âœ… **AI-powered suggestions** for data quality improvement\n",
    "- âœ… **Interactive visualizations** for insights\n",
    "- âœ… **Scalable architecture** ready for production"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
