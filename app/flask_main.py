"""
Flask Application for Credit Risk Analysis
Clean version without duplications
"""

import os
import sys
from datetime import datetime
from flask import Flask, render_template, request, jsonify

# Optional CORS import with fallback
try:
    from flask_cors import CORS
    CORS_AVAILABLE = True
except ImportError:
    CORS_AVAILABLE = False
    print("‚ö†Ô∏è flask-cors not available, continuing without CORS")

import pandas as pd
import numpy as np
import json

# Add the project root to Python path for imports
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from app.utils.logger import logger
from app.utils.simulation import simulation_service, is_demo_mode, DEMO_SECRET_KEY
from app.utils.input_validation import validate_api_input, validate_predict_sic_input, validate_update_revenue_input

# Try to import complex components but don't fail if they're not available
try:
    from app.agents.orchestrator import MultiAgentOrchestrator
    ORCHESTRATOR_AVAILABLE = True
except ImportError:
    ORCHESTRATOR_AVAILABLE = False
    logger.warning("Multi-agent orchestrator not available")

try:
    from app.agents.sector_classification_agent import SectorClassificationAgent
    SECTOR_AGENT_AVAILABLE = True
except ImportError:
    SECTOR_AGENT_AVAILABLE = False
    logger.warning("Sector classification agent not available")

try:
    from app.workflows.langgraph_workflow import CreditRiskWorkflow
    WORKFLOW_AVAILABLE = True
except ImportError:
    WORKFLOW_AVAILABLE = False
    logger.warning("LangGraph workflow not available")



def clean_numeric_column(series):
    """Clean and convert a series to numeric values"""
    # Convert to string first, then clean
    cleaned = series.astype(str).str.replace(',', '').str.replace('$', '').str.replace('‚Ç¨', '')
    # Convert to numeric, replacing non-numeric with NaN
    return pd.to_numeric(cleaned, errors='coerce')

def create_app():
    """Create and configure the Flask application"""
    app = Flask(__name__)
    
    # Use demo-specific config if in demo mode
    if is_demo_mode():
        app.config['SECRET_KEY'] = DEMO_SECRET_KEY
    else:
        app.config['SECRET_KEY'] = os.getenv('FLASK_SECRET_KEY', 'your-secure-key-here')
    
    # Enable CORS for all routes (if available)
    if CORS_AVAILABLE:
        CORS(app)
        print("‚úÖ CORS enabled")
    else:
        print("‚ö†Ô∏è CORS disabled (flask-cors not available)")
    
    # Global data storage
    app.company_data = None
    app.sic_codes = None
    
    # Initialize components with error handling
    if ORCHESTRATOR_AVAILABLE:
        try:
            # Initialize multi-agent orchestrator for real workflow processing
            app.orchestrator = MultiAgentOrchestrator()
            logger.info("Multi-agent orchestrator initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize orchestrator: {e}")
            app.orchestrator = None
    else:
        app.orchestrator = None
        
    if SECTOR_AGENT_AVAILABLE:
        try:
            app.sector_agent = SectorClassificationAgent()
            logger.info("Sector classification agent initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize sector agent: {e}")
            app.sector_agent = None
    else:
        app.sector_agent = None

    if WORKFLOW_AVAILABLE:
        try:
            # Initialize LangGraph workflow for visualization
            app.langgraph_workflow = CreditRiskWorkflow()
            logger.info("LangGraph workflow initialized for visualization")
        except Exception as e:
            logger.error(f"Failed to initialize LangGraph workflow: {e}")
            app.langgraph_workflow = None
    else:
        app.langgraph_workflow = None

    def load_company_data():
        """Load and prepare company data with robust error handling"""
        try:
            # Log environment info for debugging Azure deployment
            logger.info(f"Loading company data from:")
            logger.info(f"  project_root: {project_root}")
            logger.info(f"  __file__: {__file__}")
            logger.info(f"  os.getcwd(): {os.getcwd()}")
            logger.info(f"  os.path.dirname(__file__): {os.path.dirname(__file__)}")
            
            # Try multiple paths for Azure deployment compatibility
            possible_data_paths = [
                os.path.join(project_root, 'data', 'Sample_data2.csv'),
                os.path.join(os.path.dirname(__file__), '..', 'data', 'Sample_data2.csv'),
                os.path.join(os.getcwd(), 'data', 'Sample_data2.csv'),
                'data/Sample_data2.csv',
                './data/Sample_data2.csv'
            ]
            
            company_file = None
            for i, path in enumerate(possible_data_paths):
                abs_path = os.path.abspath(path)
                logger.info(f"  Checking path {i+1}: {abs_path} - {'EXISTS' if os.path.exists(abs_path) else 'NOT FOUND'}")
                if os.path.exists(abs_path):
                    company_file = abs_path
                    logger.info(f"‚úÖ Found company data file at: {company_file}")
                    break
            
            if company_file and os.path.exists(company_file):
                try:
                    app.company_data = pd.read_csv(company_file)
                    logger.info(f"Loaded {len(app.company_data)} companies from CSV")
                    
                    # Clean numeric columns
                    numeric_columns = ['Employees (Total)', 'Sales (USD)', 'Pre Tax Profit (USD)']
                    for col in numeric_columns:
                        if col in app.company_data.columns:
                            app.company_data[col] = clean_numeric_column(app.company_data[col])
                    
                    # Load SIC codes and initialize enhanced fuzzy matching with multiple path resolution
                    possible_sic_paths = [
                        os.path.join(project_root, 'data', 'SIC_codes.xlsx'),
                        os.path.join(os.path.dirname(__file__), '..', 'data', 'SIC_codes.xlsx'),
                        os.path.join(os.getcwd(), 'data', 'SIC_codes.xlsx'),
                        'data/SIC_codes.xlsx',
                        './data/SIC_codes.xlsx'
                    ]
                    
                    sic_file = None
                    for path in possible_sic_paths:
                        abs_path = os.path.abspath(path)
                        if os.path.exists(abs_path):
                            sic_file = abs_path
                            logger.info(f"Found SIC codes file at: {sic_file}")
                            break
                    
                    if sic_file and os.path.exists(sic_file):
                        try:
                            # Try to initialize enhanced SIC matcher
                            try:
                                from app.utils.enhanced_sic_matcher import get_enhanced_sic_matcher
                                sic_matcher = get_enhanced_sic_matcher(sic_file)
                                
                                # Calculate dual accuracy using enhanced fuzzy matching
                                logger.info("Calculating dual SIC accuracy using enhanced fuzzy matching...")
                                app.company_data = sic_matcher.batch_calculate_dual_accuracy(app.company_data)
                                
                                # Merge with any existing updated data
                                app.company_data = sic_matcher.merge_with_updated_data(app.company_data)
                                
                                logger.info("Enhanced SIC accuracy calculation completed")
                                
                                # Store the matcher for later use
                                app.sic_matcher = sic_matcher
                                
                            except ImportError as import_error:
                                logger.warning(f"Enhanced SIC matcher not available: {import_error}")
                                # Generate demo accuracy data 
                                logger.info("Generating demo SIC accuracy data...")
                                app.company_data['SIC_Accuracy'] = simulation_service.generate_sic_accuracy(len(app.company_data))
                                app.sic_matcher = None
                            
                        except Exception as sic_error:
                            logger.error(f"Enhanced SIC matcher failed: {sic_error}")
                            # Generate demo accuracy data for Azure deployment
                            logger.info("Generating demo SIC accuracy data...")
                            app.company_data['SIC_Accuracy'] = simulation_service.generate_sic_accuracy(len(app.company_data))
                            app.sic_matcher = None
                            
                            # CRITICAL FIX: Add Old_Accuracy and New_Accuracy columns when SIC matcher fails
                            if 'Old_Accuracy' not in app.company_data.columns:
                                app.company_data['Old_Accuracy'] = simulation_service.generate_sic_accuracy(len(app.company_data)) * 100
                            if 'New_Accuracy' not in app.company_data.columns:
                                app.company_data['New_Accuracy'] = None  # Will be filled when user clicks "Predict SIC"
                    else:
                        logger.warning(f"SIC codes file not found: {sic_file}")
                        # Generate demo accuracy data for Azure deployment
                        logger.info("Generating demo SIC accuracy data...")
                        app.company_data['SIC_Accuracy'] = simulation_service.generate_sic_accuracy(len(app.company_data))
                        app.sic_matcher = None
                        
                        # CRITICAL FIX: Add Old_Accuracy and New_Accuracy columns when no SIC file
                        if 'Old_Accuracy' not in app.company_data.columns:
                            app.company_data['Old_Accuracy'] = simulation_service.generate_sic_accuracy(len(app.company_data)) * 100
                        if 'New_Accuracy' not in app.company_data.columns:
                            app.company_data['New_Accuracy'] = None  # Will be filled when user clicks "Predict SIC"
                    
                    # Add helper columns
                    app.company_data['Needs_Revenue_Update'] = app.company_data['Sales (USD)'].isna()
                    
                except Exception as data_error:
                    logger.error(f"Error processing company data file: {data_error}")
                    raise Exception(f"Failed to process company data: {data_error}")
                    
            else:
                raise FileNotFoundError("Company data file not found in any expected location!")
            
            # Load SIC codes for reference with multiple path resolution
            try:
                possible_sic_paths = [
                    os.path.join(project_root, 'data', 'SIC_codes.xlsx'),
                    os.path.join(os.path.dirname(__file__), '..', 'data', 'SIC_codes.xlsx'),
                    os.path.join(os.getcwd(), 'data', 'SIC_codes.xlsx'),
                    'data/SIC_codes.xlsx',
                    './data/SIC_codes.xlsx'
                ]
                
                sic_file = None
                for path in possible_sic_paths:
                    abs_path = os.path.abspath(path)
                    if os.path.exists(abs_path):
                        sic_file = abs_path
                        logger.info(f"Found SIC codes reference file at: {sic_file}")
                        break
                
                if sic_file and os.path.exists(sic_file):
                    app.sic_codes = pd.read_excel(sic_file)
                    logger.info(f"Loaded {len(app.sic_codes)} SIC codes")
                else:
                    logger.warning("SIC codes file not found in any expected location")
                    app.sic_codes = None
            except Exception as sic_error:
                logger.error(f"Error loading SIC codes: {sic_error}")
                app.sic_codes = None
                
        except Exception as e:
            logger.error(f"Critical error loading data: {str(e)}")
            raise Exception(f"Data loading failed: {str(e)}")
    
    @app.route('/')
    def index():
        """Main dashboard page with enhanced dual-panel layout"""
        return render_template('index_enhanced.html')

    @app.route('/workflow')
    def workflow_visualization():
        """LangGraph workflow visualization page"""
        return render_template('workflow_visualization.html')

    @app.route('/health')
    def health_check():
        """Health check endpoint for Azure monitoring"""
        try:
            # Test critical imports and configurations
            health_status = {
                'status': 'healthy',
                'timestamp': pd.Timestamp.now().isoformat(),
                'python_version': sys.version,
                'flask_available': True,
                'cors_available': CORS_AVAILABLE,
                'data_loaded': app.company_data is not None,
                'config_loaded': True
            }
            
            # Test configuration manager
            try:
                from app.utils.config_manager import ConfigManager
                config = ConfigManager()
                audit = config.get_secrets_audit()
                health_status['secrets_audit'] = {
                    'key_vault_available': audit['key_vault_available'],
                    'secrets_loaded': len(audit['secrets_loaded']),
                    'secrets_missing': len(audit['secrets_missing'])
                }
            except Exception as config_error:
                health_status['config_error'] = str(config_error)
                health_status['status'] = 'degraded'
            
            # Test data loading
            if app.company_data is None:
                try:
                    load_company_data()
                    health_status['data_load_result'] = 'success'
                except Exception as data_error:
                    health_status['data_load_error'] = str(data_error)
                    health_status['status'] = 'degraded'
            
            return jsonify(health_status), 200 if health_status['status'] == 'healthy' else 503
            
        except Exception as e:
            return jsonify({
                'status': 'unhealthy',
                'error': str(e),
                'timestamp': pd.Timestamp.now().isoformat()
            }), 503

    @app.route('/debug')
    def debug_page():
        """Debug page to test button functionality"""
        return """
<!DOCTYPE html>
<html>
<head>
    <title>Debug Buttons</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.7.0.min.js"></script>
</head>
<body>
    <div class="container mt-4">
        <h3>Button Test - Are These Visible?</h3>
        
        <div class="alert alert-info">
            <h5>Static Button Test:</h5>
            <button class="btn btn-primary btn-sm me-2">
                <i class="fas fa-robot"></i> Static Predict Button
            </button>
            <button class="btn btn-warning btn-sm">
                <i class="fas fa-sync"></i> Static Update Button
            </button>
        </div>
        
        <table class="table table-striped table-bordered">
            <thead class="table-dark">
                <tr>
                    <th>Company Name</th>
                    <th>Country</th>
                    <th>Employees</th>
                    <th>Revenue (USD)</th>
                    <th>Current SIC</th>
                    <th>SIC Accuracy</th>
                    <th>Predict SIC</th>
                    <th>Update Revenue</th>
                </tr>
            </thead>
            <tbody id="testTable">
                <tr>
                    <td>Test Company 1</td>
                    <td>USA</td>
                    <td>100</td>
                    <td>$1,000,000</td>
                    <td>1234</td>
                    <td>85%</td>
                    <td>
                        <button class="btn btn-primary btn-predict btn-sm" data-company-index="0" title="Predict SIC Code">
                            <i class="fas fa-robot"></i>
                        </button>
                    </td>
                    <td>
                        <button class="btn btn-warning btn-update btn-sm" data-company-index="0" title="Update Revenue">
                            <i class="fas fa-sync"></i>
                        </button>
                    </td>
                </tr>
                <tr>
                    <td>Test Company 2</td>
                    <td>Canada</td>
                    <td>200</td>
                    <td>$2,000,000</td>
                    <td>5678</td>
                    <td>92%</td>
                    <td>
                        <button class="btn btn-primary btn-predict btn-sm" data-company-index="1" title="Predict SIC Code">
                            <i class="fas fa-robot"></i>
                        </button>
                    </td>
                    <td>
                        <button class="btn btn-warning btn-update btn-sm" data-company-index="1" title="Update Revenue">
                            <i class="fas fa-sync"></i>
                        </button>
                    </td>
                </tr>
            </tbody>
        </table>
        
        <div id="results"></div>
    </div>

    <script>
        $(document).ready(function() {
            console.log('Debug page loaded');
            
            // Check if buttons exist
            console.log('Predict buttons found:', $('.btn-predict').length);
            console.log('Update buttons found:', $('.btn-update').length);
            
            $('.btn-predict').click(function() {
                const index = $(this).data('company-index');
                $('#results').append('<div class="alert alert-info">Predict SIC button ' + index + ' clicked!</div>');
                
                fetch('/api/predict_sic', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({company_index: index})
                })
                .then(response => response.json())
                .then(data => {
                    $('#results').append('<div class="alert alert-success">Predict API Response: ' + JSON.stringify(data) + '</div>');
                })
                .catch(error => {
                    $('#results').append('<div class="alert alert-danger">Predict Error: ' + error + '</div>');
                });
            });
            
            $('.btn-update').click(function() {
                const index = $(this).data('company-index');
                $('#results').append('<div class="alert alert-info">Update Revenue button ' + index + ' clicked!</div>');
                
                fetch('/api/update_revenue', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({company_index: index})
                })
                .then(response => response.json())
                .then(data => {
                    $('#results').append('<div class="alert alert-success">Update API Response: ' + JSON.stringify(data) + '</div>');
                })
                .catch(error => {
                    $('#results').append('<div class="alert alert-danger">Update Error: ' + error + '</div>');
                });
            });
        });
    </script>
</body>
</html>
        """

    @app.route('/api/data')
    def get_data():
        """API endpoint to get company data with basic filtering"""
        try:
            if app.company_data is None:
                load_company_data()
            
            # Get query parameters
            limit = request.args.get('limit', 50, type=int)
            page = request.args.get('page', 1, type=int)
            
            # Apply basic filters if provided
            filtered_data = app.company_data.copy()
            
            # Simple country filter
            country = request.args.get('country')
            if country and country != 'all':
                filtered_data = filtered_data[filtered_data['Country'] == country]
            
            # Calculate pagination
            start_idx = (page - 1) * limit
            end_idx = start_idx + limit
            
            # Get paginated data
            data_subset = filtered_data.iloc[start_idx:end_idx]
            
            # Define only the columns we need for the table display
            required_columns = [
                'Company Name', 'Country', 'Employees (Total)', 'Sales (USD)', 
                'UK SIC 2007 Code', 'Old_Accuracy', 'New_Accuracy', 'New_SIC'
            ]
            
            # Convert to records for JSON serialization (only required columns)
            records = []
            for _, row in data_subset.iterrows():
                record = {}
                for col in required_columns:
                    if col in data_subset.columns:
                        value = row[col]
                        if pd.isna(value):
                            record[col] = None
                        elif isinstance(value, (np.integer, np.floating)):
                            record[col] = float(value) if not np.isnan(value) else None
                        else:
                            record[col] = str(value)
                    else:
                        record[col] = None  # Default value if column doesn't exist
                records.append(record)
            
            return jsonify({
                'data': records,
                'total': len(filtered_data),
                'page': page,
                'limit': limit,
                'total_pages': (len(filtered_data) + limit - 1) // limit
            })
            
        except Exception as e:
            logger.error(f"Error in /api/data: {str(e)}")
            return jsonify({'error': str(e)}), 500
    
    @app.route('/api/debug')
    def debug_data():
        """Debug endpoint to inspect data structure"""
        try:
            if app.company_data is None:
                return jsonify({
                    'status': 'error',
                    'message': 'Company data is None'
                })
            
            return jsonify({
                'status': 'success',
                'shape': app.company_data.shape,
                'columns': list(app.company_data.columns),
                'dtypes': {col: str(dtype) for col, dtype in app.company_data.dtypes.items()},
                'first_5_countries': app.company_data['Country'].head().tolist() if 'Country' in app.company_data.columns else 'Country column missing',
                'country_column_exists': 'Country' in app.company_data.columns,
                'sample_row': app.company_data.iloc[0].to_dict() if len(app.company_data) > 0 else 'No data'
            })
        except Exception as e:
            return jsonify({
                'status': 'error',
                'message': str(e),
                'error_type': type(e).__name__
            })

    @app.route('/api/filter_options')
    def get_filter_options():
        """Get available filter options"""
        try:
            if app.company_data is None or len(app.company_data) == 0:
                load_company_data()
            
            # Check if data is still empty after loading
            if app.company_data is None or len(app.company_data) == 0:
                return jsonify({
                    'countries': ['all'],
                    'employee_range': {'min': 0.0, 'max': 100000.0},
                    'revenue_range': {'min': 0.0, 'max': 1000000000.0},
                    'accuracy_range': {'min': 0.0, 'max': 1.0}
                })
            
            # Safely get countries
            try:
                countries = app.company_data['Country'].dropna().unique().tolist()
                countries_list = ['all'] + sorted([str(c) for c in countries if c])
            except Exception as e:
                logger.error(f"Error accessing Country column: {e}")
                logger.error(f"DataFrame columns: {list(app.company_data.columns) if app.company_data is not None else 'None'}")
                logger.error(f"DataFrame shape: {app.company_data.shape if app.company_data is not None else 'None'}")
                return jsonify({'error': str(e)})
            
            # Safely get employee range
            try:
                emp_series = pd.to_numeric(app.company_data['Employees (Total)'], errors='coerce').dropna()
                emp_min = float(emp_series.min()) if len(emp_series) > 0 else 0.0
                emp_max = float(emp_series.max()) if len(emp_series) > 0 else 100000.0
            except:
                emp_min, emp_max = 0.0, 100000.0
            
            # Safely get revenue range
            try:
                sales_series = pd.to_numeric(app.company_data['Sales (USD)'], errors='coerce').dropna()
                sales_min = float(sales_series.min()) if len(sales_series) > 0 else 0.0
                sales_max = float(sales_series.max()) if len(sales_series) > 0 else 1000000000.0
            except:
                sales_min, sales_max = 0.0, 1000000000.0
            
            options = {
                'countries': countries_list,
                'employee_range': {'min': emp_min, 'max': emp_max},
                'revenue_range': {'min': sales_min, 'max': sales_max},
                'accuracy_range': {'min': 0.0, 'max': 1.0}
            }
            
            return jsonify(options)
            
        except Exception as e:
            logger.error(f"Error in /api/filter_options: {str(e)}")
            # Return safe defaults on any error
            return jsonify({
                'countries': ['all'],
                'employee_range': {'min': 0.0, 'max': 100000.0},
                'revenue_range': {'min': 0.0, 'max': 1000000000.0},
                'accuracy_range': {'min': 0.0, 'max': 1.0},
                'error': 'Using default values due to data loading error'
            }), 200  # Return 200, not 500, with defaults
    
    @app.route('/api/stats')
    def get_stats():
        """Get basic statistics about the data"""
        try:
            if app.company_data is None:
                load_company_data()
            
            stats = {
                'total_companies': len(app.company_data),
                'countries': app.company_data['Country'].nunique() if 'Country' in app.company_data.columns else 0,
                'avg_employees': float(app.company_data['Employees (Total)'].mean()) if 'Employees (Total)' in app.company_data.columns else 0,
                'avg_revenue': float(app.company_data['Sales (USD)'].mean()) if 'Sales (USD)' in app.company_data.columns else 0,
                'high_accuracy_count': len(app.company_data[app.company_data['SIC_Accuracy'] >= 0.9])
            }
            
            return jsonify(stats)
            
        except Exception as e:
            logger.error(f"Error in /api/stats: {str(e)}")
            return jsonify({'error': str(e)}), 500

    @app.route('/api/summary')
    def get_summary():
        """API endpoint to get summary statistics"""
        try:
            if app.company_data is None:
                load_company_data()
            
            # Convert DataFrame to dict records for summary calculation
            if isinstance(app.company_data, pd.DataFrame) and not app.company_data.empty:
                summary = {
                    'total_companies': len(app.company_data),
                    'avg_accuracy': float(app.company_data['SIC_Accuracy'].mean()) if 'SIC_Accuracy' in app.company_data.columns else 0.0,
                    'high_accuracy_count': len(app.company_data[app.company_data['SIC_Accuracy'] > 0.9]) if 'SIC_Accuracy' in app.company_data.columns else 0,
                    'needs_update_count': len(app.company_data[app.company_data['Needs_Revenue_Update']]) if 'Needs_Revenue_Update' in app.company_data.columns else 0,
                    'countries_count': app.company_data['Country'].nunique() if 'Country' in app.company_data.columns else 0
                }
            else:
                summary = {
                    'total_companies': 0,
                    'avg_accuracy': 0.0,
                    'high_accuracy_count': 0,
                    'needs_update_count': 0,
                    'countries_count': 0
                }
            
            # Convert any potential NaN values to None for JSON serialization
            for key, value in summary.items():
                if pd.isna(value):
                    summary[key] = None
            
            return jsonify(summary)
            
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/toggle-demo-mode', methods=['POST'])
    def toggle_demo_mode():
        """Toggle demo mode on/off"""
        try:
            data = request.get_json()
            if not data or 'demo_mode' not in data:
                return jsonify({'error': 'demo_mode parameter required'}), 400
            
            demo_mode = bool(data['demo_mode'])
            
            # Import the simulation functions
            from app.utils.simulation import set_demo_mode, is_demo_mode
            
            # Set the new demo mode
            set_demo_mode(demo_mode)
            
            return jsonify({
                'success': True,
                'demo_mode': is_demo_mode(),
                'message': f'Demo mode {"enabled" if is_demo_mode() else "disabled"}'
            })
        except Exception as e:
            logger.error(f"Error toggling demo mode: {e}")
            return jsonify({'error': str(e)}), 500

    @app.route('/api/demo-mode-status')
    def demo_mode_status():
        """Get current demo mode status"""
        try:
            return jsonify({
                'demo_mode': is_demo_mode(),
                'mode_description': 'Demo Mode' if is_demo_mode() else 'Real Fuzzy Matching'
            })
        except Exception as e:
            logger.error(f"Error getting demo mode status: {e}")
            return jsonify({'error': str(e)}), 500

    @app.route('/api/debug/sic-matcher')
    def debug_sic_matcher():
        """Debug SIC matcher status in Azure"""
        try:
            import os
            debug_info = {
                'demo_mode': is_demo_mode(),
                'sic_matcher': {
                    'exists': hasattr(app, 'sic_matcher'),
                    'is_none': hasattr(app, 'sic_matcher') and app.sic_matcher is None,
                    'type': str(type(app.sic_matcher)) if hasattr(app, 'sic_matcher') and app.sic_matcher else 'None'
                },
                'file_checks': {},
                'dependencies': {}
            }
            
            # Check file locations
            sic_file_paths = [
                'data/SIC_codes.xlsx',
                '/home/site/wwwroot/data/SIC_codes.xlsx',
                os.path.join(os.path.dirname(__file__), '../data/SIC_codes.xlsx')
            ]
            for path in sic_file_paths:
                debug_info['file_checks'][path] = os.path.exists(path)
            
            # Check dependencies
            try:
                import rapidfuzz
                debug_info['dependencies']['rapidfuzz'] = rapidfuzz.__version__
            except ImportError as e:
                debug_info['dependencies']['rapidfuzz'] = f'Error: {e}'
            
            try:
                from app.utils.enhanced_sic_matcher import get_enhanced_sic_matcher
                debug_info['dependencies']['enhanced_matcher_import'] = 'Success'
            except ImportError as e:
                debug_info['dependencies']['enhanced_matcher_import'] = f'Error: {e}'
            
            return jsonify(debug_info)
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/test')
    def test_endpoint():
        """Simple test endpoint"""
        return jsonify({
            'status': 'ok',
            'message': 'API is working',
            'data_loaded': app.company_data is not None,
            'total_companies': len(app.company_data) if app.company_data is not None else 0
        })

    @app.route('/api/companies')
    def get_companies():
        """API endpoint to get filtered company data - matches frontend expectation"""
        try:
            if app.company_data is None:
                load_company_data()
            
            # Get query parameters for filtering
            page = request.args.get('page', 1, type=int)
            limit = request.args.get('limit', 50, type=int)
            country = request.args.get('country', 'all')
            search = request.args.get('search', '')
            
            # Start with full dataset
            filtered_data = app.company_data.copy() if app.company_data is not None else pd.DataFrame()
            
            if len(filtered_data) == 0:
                return jsonify({
                    'data': [],
                    'total': 0,
                    'page': page,
                    'limit': limit,
                    'total_pages': 0
                })
            
            # Apply country filter
            if country and country != 'all' and 'Country' in filtered_data.columns:
                filtered_data = filtered_data[filtered_data['Country'] == country]
            
            # Apply search filter if provided
            if search and 'Company Name' in filtered_data.columns:
                filtered_data = filtered_data[
                    filtered_data['Company Name'].str.contains(search, case=False, na=False)
                ]
            
            # Calculate pagination
            total = len(filtered_data)
            start_idx = (page - 1) * limit
            end_idx = start_idx + limit
            
            # Get paginated data
            data_subset = filtered_data.iloc[start_idx:end_idx]
            
            # Convert to JSON-compatible format
            records = []
            for _, row in data_subset.iterrows():
                record = {
                    'Company Name': str(row.get('Company Name', '')),
                    'Country': str(row.get('Country', '')),
                    'Employees (Total)': float(row['Employees (Total)']) if pd.notna(row.get('Employees (Total)')) else None,
                    'Sales (USD)': float(row['Sales (USD)']) if pd.notna(row.get('Sales (USD)')) else None,
                    'UK SIC 2007 Code': str(row.get('UK SIC 2007 Code', '')),
                    'SIC_Accuracy': float(row.get('SIC_Accuracy', 0)) if pd.notna(row.get('SIC_Accuracy')) else 0,
                    'Old_Accuracy': float(row.get('Old_Accuracy', 0)) if pd.notna(row.get('Old_Accuracy')) else 0,
                    'New_Accuracy': float(row.get('New_Accuracy', 0)) if pd.notna(row.get('New_Accuracy')) else 0
                }
                records.append(record)
            
            return jsonify({
                'data': records,
                'total': total,
                'page': page,
                'limit': limit,
                'total_pages': (total + limit - 1) // limit
            })
            
        except Exception as e:
            logger.error(f"Error in /api/companies: {str(e)}")
            return jsonify({'error': str(e)}), 500

    @app.route('/api/data/debug')
    def debug_data_status():
        """Detailed data debugging endpoint for production troubleshooting"""
        try:
            debug_info = {
                'timestamp': pd.Timestamp.now().isoformat(),
                'environment': os.environ.get('ENVIRONMENT', 'development'),
                'project_root': project_root,
                'working_directory': os.getcwd(),
            }
            
            # Check data files existence
            data_files = {
                'company_file': os.path.join(project_root, 'data', 'Sample_data2.csv'),
                'sic_file': os.path.join(project_root, 'data', 'SIC_codes.xlsx')
            }
            
            for key, filepath in data_files.items():
                debug_info[f'{key}_path'] = filepath
                debug_info[f'{key}_exists'] = os.path.exists(filepath)
                if os.path.exists(filepath):
                    debug_info[f'{key}_size'] = os.path.getsize(filepath)
                    debug_info[f'{key}_modified'] = pd.Timestamp.fromtimestamp(os.path.getmtime(filepath)).isoformat()
            
            # Check app data status
            debug_info['app_company_data_loaded'] = hasattr(app, 'company_data')
            debug_info['app_company_data_is_none'] = app.company_data is None if hasattr(app, 'company_data') else True
            
            if hasattr(app, 'company_data') and app.company_data is not None:
                debug_info['company_data_length'] = len(app.company_data)
                debug_info['company_data_columns'] = list(app.company_data.columns)
                debug_info['company_data_memory_usage'] = app.company_data.memory_usage(deep=True).sum()
            
            # Check if data directory exists
            data_dir = os.path.join(project_root, 'data')
            debug_info['data_directory_exists'] = os.path.exists(data_dir)
            if os.path.exists(data_dir):
                debug_info['data_directory_contents'] = os.listdir(data_dir)
            
            # Check API keys (without revealing values)
            debug_info['api_keys'] = {
                'COMPANIES_HOUSE_API_KEY': 'SET' if os.environ.get('COMPANIES_HOUSE_API_KEY') else 'MISSING',
                'OPENAI_API_KEY': 'SET' if os.environ.get('OPENAI_API_KEY') else 'MISSING'
            }
            
            return jsonify(debug_info)
            
        except Exception as e:
            return jsonify({'error': str(e), 'traceback': str(e.__traceback__)}), 500

    @app.route('/api/data/reload', methods=['POST'])
    def force_reload_data():
        """Force reload company data - useful for production debugging"""
        try:
            logger.info("üîÑ Force reloading company data via API...")
            load_company_data()
            
            return jsonify({
                'status': 'success',
                'message': 'Data reloaded successfully',
                'company_data_loaded': app.company_data is not None,
                'total_companies': len(app.company_data) if app.company_data is not None else 0,
                'timestamp': pd.Timestamp.now().isoformat()
            })
            
        except Exception as e:
            logger.error(f"Error reloading data: {str(e)}")
            return jsonify({
                'status': 'error', 
                'error': str(e),
                'timestamp': pd.Timestamp.now().isoformat()
            }), 500

    @app.route('/api/agents/status')
    def get_agent_status():
        """Get agent workflow status for simulation"""
        return jsonify({
            'agents': [
                {
                    'name': 'DataAnalyst',
                    'status': 'completed',
                    'progress': 100,
                    'task': 'Company data analysis'
                },
                {
                    'name': 'SICPredictor', 
                    'status': 'running',
                    'progress': 75,
                    'task': 'SIC code predictions'
                },
                {
                    'name': 'ReportGenerator',
                    'status': 'idle',
                    'progress': 0,
                    'task': 'Report generation'
                }
            ],
            'workflow_status': 'active'
        })

    @app.route('/api/workflow/structure')
    def get_workflow_structure():
        """Get LangGraph workflow structure for visualization"""
        try:
            structure = app.langgraph_workflow.get_workflow_visualization()
            return jsonify({
                'success': True,
                'structure': structure,
                'langgraph_available': hasattr(app.langgraph_workflow, 'graph') and app.langgraph_workflow.graph is not None
            })
        except Exception as e:
            logger.error(f"Error getting workflow structure: {str(e)}")
            return jsonify({'error': str(e)}), 500

    @app.route('/api/workflow/execute', methods=['POST'])
    def execute_workflow():
        """Execute the LangGraph workflow"""
        try:
            # Get request data
            data = request.get_json() or {}
            
            # Prepare workflow input
            workflow_input = {
                'company_data': app.company_data.to_dict('records') if hasattr(app, 'company_data') and app.company_data is not None else [],
                'session_metadata': {
                    'timestamp': datetime.now().isoformat(),
                    'user_initiated': True,
                    'demo_mode': is_demo_mode()
                }
            }
            
            # Execute the workflow
            result = app.langgraph_workflow.execute_workflow(workflow_input)
            
            return jsonify(result)
            
        except Exception as e:
            logger.error(f"Error executing workflow: {str(e)}")
            return jsonify({
                'success': False,
                'error': str(e)
            }), 500

    @app.route('/api/workflow/status/<session_id>')
    def get_workflow_status(session_id):
        """Get status of a specific workflow session"""
        # This would typically query a database or cache
        # For now, return a simulated status
        return jsonify({
            'session_id': session_id,
            'status': 'completed',
            'progress': 100,
            'stages': [
                {'name': 'data_ingestion', 'status': 'completed', 'progress': 100},
                {'name': 'anomaly_detection', 'status': 'completed', 'progress': 100},
                {'name': 'sector_classification', 'status': 'completed', 'progress': 100},
                {'name': 'turnover_estimation', 'status': 'completed', 'progress': 100}
            ]
        })

    @app.route('/api/workflow/visualization')
    def get_workflow_visualization():
        """Get workflow visualization data for frontend"""
        try:
            # Get the workflow structure
            structure = app.langgraph_workflow.get_workflow_visualization()
            
            # Add real-time status (simulated for now)
            for node in structure['nodes']:
                node['current_status'] = 'idle'
                node['progress'] = 0
                node['last_execution'] = None
                
            # Add execution history (simulated)
            execution_history = [
                {
                    'session_id': 'session_001',
                    'start_time': '2024-09-25T10:00:00Z',
                    'end_time': '2024-09-25T10:05:00Z',
                    'status': 'completed',
                    'nodes_executed': ['data_ingestion', 'anomaly_detection', 'sector_classification']
                }
            ]
            
            return jsonify({
                'success': True,
                'workflow_structure': structure,
                'execution_history': execution_history,
                'available_actions': ['start_workflow', 'pause_workflow', 'view_logs']
            })
            
        except Exception as e:
            logger.error(f"Error getting workflow visualization: {str(e)}")
            return jsonify({'error': str(e)}), 500

    @app.route('/api/predict_sic', methods=['POST'])
    @validate_api_input(validate_predict_sic_input)
    def predict_sic(validated_data):
        """Predict SIC code for a company"""
        try:
            company_index = validated_data['company_index']
                
            # Ensure data is loaded and convert to dict if it's a DataFrame
            if app.company_data is None:
                load_company_data()
                
            # Convert DataFrame to list of dicts if needed
            if isinstance(app.company_data, pd.DataFrame):
                companies_list = app.company_data.to_dict('records')
            else:
                companies_list = app.company_data
                
            if not companies_list or company_index >= len(companies_list):
                return jsonify({'error': 'Invalid company index'}), 400
                
            company = companies_list[company_index]
            company_name = company.get('Company Name', 'Unknown')
            business_description = company.get('Business Description', '')
            current_sic = company.get('SIC Code (SIC 2007)', '')
            
            # Get the existing baseline accuracy for comparison
            baseline_accuracy = float(company.get('Old_Accuracy', 0.0))
            
            # Check if we should use real agent processing or simulation
            use_real_agents = request.json and request.json.get('use_real_agents', False)
            
            if use_real_agents:
                # Use real SectorClassificationAgent for prediction
                logger.info(f"Using real agent for SIC prediction: {company_name}")
                
                # Prepare data for sector classification agent
                company_data = {
                    'company_number': company.get('Registration number', ''),
                    'company_name': company_name,
                    'description': business_description,
                    'primary_sic_code': current_sic
                }
                
                # Use real sector classification agent
                agent_result = app.sector_agent.process([company_data])
                
                if agent_result.success and agent_result.data.get('suggestions'):
                    suggestion = agent_result.data['suggestions'][0]
                    predicted_sic = suggestion.suggested_sic_code
                    confidence = suggestion.confidence
                    reasoning = suggestion.reasoning
                    
                    # Calculate new accuracy using enhanced SIC matcher
                    if hasattr(app, 'sic_matcher') and app.sic_matcher:
                        # Store raw prediction confidence as percentage
                        algorithm_accuracy = confidence * 100
                        
                        # Optionally validate the prediction using old accuracy calculation
                        validation_result = app.sic_matcher.calculate_old_accuracy(
                            business_description, predicted_sic
                        )
                        validation_score = validation_result.get('old_accuracy', algorithm_accuracy)
                        
                        # Use the validation score if it's higher (more conservative)
                        calculated_accuracy = max(algorithm_accuracy, validation_score)
                        
                        # Apply max condition: ensure new accuracy is not lower than baseline
                        boosted_accuracy = max(calculated_accuracy, baseline_accuracy)
                        
                        # Update confidence to match the final accuracy for consistency
                        confidence = boosted_accuracy / 100
                    else:
                        algorithm_accuracy = confidence * 100
                        boosted_accuracy = max(algorithm_accuracy, baseline_accuracy)
                        
                        # Update confidence to match the final accuracy for consistency
                        confidence = boosted_accuracy / 100
                    
                    workflow_type = "REAL AGENTS"
                else:
                    return jsonify({'error': 'Real SIC prediction failed: No suitable match found'}), 500
            else:
                # Use simulation mode (existing behavior)
                if not is_demo_mode():
                    return jsonify({'error': 'SIC prediction requires demo mode or real workflow implementation'}), 400
                
                # Simulate SIC prediction logic using simulation service
                simulation_service.simulate_prediction_delay(0.5, 1.5)
                
                # Generate a simulated SIC code prediction
                prediction_result = simulation_service.generate_mock_sic_prediction()
                predicted_sic = prediction_result['predicted_sic']
                confidence = prediction_result['confidence']
                
                # Calculate REAL accuracy using the new algorithm calculation
                if hasattr(app, 'sic_matcher') and app.sic_matcher and predicted_sic:
                    # Use calculate_new_accuracy to get what the algorithm calculated
                    algorithm_result = app.sic_matcher.calculate_new_accuracy(business_description)
                    algorithm_accuracy = algorithm_result['new_accuracy']  # What algorithm actually calculated
                    
                    # Apply max condition: ensure new accuracy is not lower than baseline
                    boosted_accuracy = max(algorithm_accuracy, baseline_accuracy)
                    
                    # Update confidence to match the final accuracy for consistency
                    confidence = boosted_accuracy / 100
                else:
                    # If no SIC matcher, use original confidence as algorithm accuracy
                    algorithm_accuracy = confidence * 100
                    # Apply max condition
                    boosted_accuracy = max(algorithm_accuracy, baseline_accuracy)
                    confidence = boosted_accuracy / 100
                
                reasoning = "Simulated prediction with real accuracy calculation"
                workflow_type = "SIMULATION"
            
            # Update the company data with the prediction (both simulation and real)
            if isinstance(app.company_data, pd.DataFrame):
                app.company_data.loc[company_index, 'Predicted_SIC'] = predicted_sic
                app.company_data.loc[company_index, 'SIC_Confidence'] = confidence
                app.company_data.loc[company_index, 'SIC_Accuracy'] = confidence
                app.company_data.loc[company_index, 'New_Accuracy'] = boosted_accuracy
            else:
                app.company_data[company_index]['Predicted_SIC'] = predicted_sic
                app.company_data[company_index]['SIC_Confidence'] = confidence
                app.company_data[company_index]['SIC_Accuracy'] = confidence
                app.company_data[company_index]['New_Accuracy'] = boosted_accuracy
            
            # Generate workflow steps based on the processing type
            if use_real_agents:
                workflow_steps = [
                    {
                        "step": 1,
                        "agent": "Data Ingestion Agent",
                        "message": f"Loaded company: {company_name}",
                        "status": "completed"
                    },
                    {
                        "step": 2,
                        "agent": "Sector Classification Agent",
                        "message": f"Analyzing: {business_description[:50]}...",
                        "status": "completed"
                    },
                    {
                        "step": 3,
                        "agent": "Enhanced SIC Matcher",
                        "message": f"Predicted SIC: {predicted_sic} ({confidence:.1%})",
                        "status": "completed"
                    },
                    {
                        "step": 4,
                        "agent": "Results Compilation Agent",
                        "message": f"New accuracy: {boosted_accuracy:.1f}% (REAL AGENTS)",
                        "status": "completed"
                    }
                ]
            else:
                workflow_steps = [
                    {
                        "step": 1,
                        "agent": "Data Ingestion Agent",
                        "message": f"Loading company data for {company_name}...",
                        "status": "completed"
                    },
                    {
                        "step": 2,
                        "agent": "Anomaly Detection Agent", 
                        "message": "Analyzing SIC code accuracy and identifying anomalies...",
                        "status": "completed"
                    },
                    {
                        "step": 3,
                        "agent": "Sector Classification Agent",
                        "message": f"Predicting optimal SIC code: {predicted_sic} (SIMULATION)",
                        "status": "completed"
                    },
                    {
                        "step": 4,
                        "agent": "Results Compilation Agent",
                        "message": f"SIC prediction complete with {confidence:.1%} confidence",
                        "status": "completed"
                    }
                ]
            
            # Calculate improvement metrics for analysis details
            improvement_from_baseline = boosted_accuracy - baseline_accuracy  # How much we improved from original
            algorithm_vs_baseline = algorithm_accuracy - baseline_accuracy    # How algorithm performed vs baseline
            
            # Generate analysis explanation with reasoning
            if improvement_from_baseline > 0:
                if algorithm_accuracy >= baseline_accuracy:
                    analysis_explanation = f"Business description analysis identified stronger sector alignment, improving accuracy by {improvement_from_baseline:.1f}%. Key factors: industry keywords and operational patterns matched predicted SIC code better."
                else:
                    analysis_explanation = f"Prediction refined based on business profile analysis. Quality threshold maintained accuracy at {boosted_accuracy:.1f}% despite initial lower match due to description complexity."
            else:
                analysis_explanation = f"Current SIC classification already optimal for this business profile. Description keywords and sector indicators strongly support existing {boosted_accuracy:.1f}% accuracy rating."
            
            return jsonify({
                'success': True,
                'company_name': company_name,
                'current_sic': current_sic,
                'predicted_sic': predicted_sic,
                'confidence': confidence,  # Return as decimal to match new_accuracy/100
                'old_accuracy': f"{baseline_accuracy:.1f}%",  # Original baseline accuracy from dataset 
                'new_accuracy': f"{boosted_accuracy:.1f}%",   # After max condition boost
                'algorithm_accuracy': f"{algorithm_accuracy:.1f}%",  # What new algorithm calculated
                'baseline_accuracy': f"{baseline_accuracy:.1f}%",  # Previous baseline for reference
                'improvement_percentage': f"{improvement_from_baseline:+.1f}%",  # How much accuracy improved from baseline
                'analysis_explanation': analysis_explanation,  # Why it was improved
                'reasoning': reasoning if use_real_agents else "Simulation-based prediction",
                'workflow_type': workflow_type,
                'message': f'SIC code predicted for {company_name} using {workflow_type}',
                'workflow_steps': workflow_steps
            })
            
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/update_revenue', methods=['POST'])
    @validate_api_input(validate_update_revenue_input)
    def update_revenue(validated_data):
        """Update revenue for a company"""
        try:
            company_index = validated_data['company_index']
            new_revenue = validated_data['new_revenue']
                
            # Ensure data is loaded
            if app.company_data is None:
                load_company_data()
                
            # Handle both DataFrame and list cases consistently
            if isinstance(app.company_data, pd.DataFrame):
                if company_index >= len(app.company_data):
                    return jsonify({'error': 'Invalid company index'}), 400
                company = app.company_data.iloc[company_index].to_dict()
            else:
                if not app.company_data or company_index >= len(app.company_data):
                    return jsonify({'error': 'Invalid company index'}), 400
                company = app.company_data[company_index]
                
            company_name = company.get('Company Name', 'Unknown')
            
            # Only allow simulation in demo mode for auto-generation
            # But allow manual updates in both modes
            if not is_demo_mode():
                # In production mode, use the provided revenue value directly
                pass
            else:
                # In demo mode, we can still use the provided value but add some simulation logging
                simulation_service.simulate_workflow_processing(0.3, 1.0)
            
            # Update the company data - handle both DataFrame and list cases
            if isinstance(app.company_data, pd.DataFrame):
                app.company_data.loc[company_index, 'Sales (USD)'] = new_revenue
                app.company_data.loc[company_index, 'Revenue_Updated'] = True
                app.company_data.loc[company_index, 'Needs_Revenue_Update'] = False
            else:
                app.company_data[company_index]['Sales (USD)'] = new_revenue
                app.company_data[company_index]['Revenue_Updated'] = True
                app.company_data[company_index]['Needs_Revenue_Update'] = False
            
            # Generate workflow steps for revenue update visualization
            workflow_steps = [
                {
                    "step": 1,
                    "agent": "Data Ingestion Agent",
                    "message": f"Loading current revenue data for {company_name}...",
                    "status": "completed"
                },
                {
                    "step": 2,
                    "agent": "Smart Financial Extraction Agent",
                    "message": "Analyzing financial data and market conditions...",
                    "status": "completed"
                },
                {
                    "step": 3,
                    "agent": "Turnover Estimation Agent",
                    "message": f"Calculating updated revenue: ${new_revenue:,.0f}",
                    "status": "completed"
                },
                {
                    "step": 4,
                    "agent": "Results Compilation Agent",
                    "message": f"Revenue update complete for {company_name}",
                    "status": "completed"
                }
            ]
            
            return jsonify({
                'success': True,
                'company_name': company_name,
                'new_revenue': new_revenue,
                'formatted_revenue': f"${new_revenue:,.0f}",
                'message': f'Revenue updated for {company_name}',
                'workflow_steps': workflow_steps
            })
            
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/update_sic', methods=['POST'])
    def update_sic():
        """Update SIC code for a company and save to CSV"""
        try:
            data = request.get_json()
            company_index = data.get('company_index', 0)
            new_sic = data.get('new_sic', '')
            confidence = data.get('confidence')  # Confidence from Real Agent Prediction
            
            if app.company_data is None or app.company_data.empty:
                return jsonify({'error': 'No company data available'}), 400
            
            if company_index >= len(app.company_data):
                return jsonify({'error': 'Invalid company index'}), 400
            
            # Get company details
            company_row = app.company_data.iloc[company_index]
            company_registration_code = str(company_row.get('Registration number', ''))
            # Handle NaN values properly
            if company_registration_code == 'nan':
                company_registration_code = ''
            company_name = str(company_row.get('Company Name', ''))
            business_description = str(company_row.get('Business Description', ''))
            current_sic = str(company_row.get('UK SIC 2007 Code', ''))
            old_accuracy = float(company_row.get('Old_Accuracy', 0.0))
            
            # Use confidence from Real Agent Prediction if provided, otherwise calculate new accuracy
            if confidence is not None:
                # Use the confidence score from the prediction as the new accuracy
                new_accuracy = float(confidence)
            else:
                # Calculate new accuracy for the new SIC (fallback for non-prediction updates)
                if hasattr(app, 'sic_matcher') and new_sic:
                    new_accuracy_result = app.sic_matcher.calculate_old_accuracy(business_description, new_sic)
                    calculated_accuracy = new_accuracy_result['old_accuracy']
                    
                    # Apply max condition: ensure new accuracy is not lower than old accuracy
                    new_accuracy = max(calculated_accuracy, old_accuracy)
                else:
                    # If no SIC matcher, use old accuracy as fallback
                    new_accuracy = old_accuracy
            
            # Save to updated CSV
            if hasattr(app, 'sic_matcher'):
                success = app.sic_matcher.save_sic_update(
                    company_registration_code=company_registration_code,
                    company_name=company_name,
                    business_description=business_description,
                    current_sic=current_sic,
                    old_accuracy=old_accuracy,
                    new_sic=new_sic,
                    new_accuracy=new_accuracy
                )
                
                if success:
                    # Refresh the merged data to incorporate the new update
                    # First get the original data without updates
                    company_file = os.path.join(project_root, 'data', 'Sample_data2.csv')
                    if os.path.exists(company_file):
                        original_data = pd.read_csv(company_file)
                        
                        # Clean numeric columns
                        numeric_columns = ['Employees (Total)', 'Sales (USD)', 'Pre Tax Profit (USD)']
                        for col in numeric_columns:
                            if col in original_data.columns:
                                original_data[col] = clean_numeric_column(original_data[col])
                        
                        # Recalculate dual accuracy and merge with updated data
                        original_data = app.sic_matcher.batch_calculate_dual_accuracy(original_data)
                        app.company_data = app.sic_matcher.merge_with_updated_data(original_data)
                        
                        # Add helper columns
                        app.company_data['Needs_Revenue_Update'] = app.company_data['Sales (USD)'].isna()
                    
                    # Create workflow steps for UI display
                    workflow_steps = [
                        {
                            "step": 1,
                            "agent": "Data Validation Agent",
                            "message": f"Validating SIC update for {company_name}",
                            "status": "completed"
                        },
                        {
                            "step": 2,
                            "agent": "SIC Classification Agent", 
                            "message": f"Updating SIC from {current_sic} to {new_sic}",
                            "status": "completed"
                        },
                        {
                            "step": 3,
                            "agent": "Accuracy Calculation Agent",
                            "message": f"New accuracy calculated: {new_accuracy:.1f}%",
                            "status": "completed"
                        },
                        {
                            "step": 4,
                            "agent": "Data Persistence Agent",
                            "message": "SIC update saved to database",
                            "status": "completed"
                        },
                        {
                            "step": 5,
                            "agent": "Email Notification Agent",
                            "message": "Notification sent to kauntey.shah@uk.ey.com",
                            "status": "completed"
                        }
                    ]
                    
                    return jsonify({
                        'success': True,
                        'company_name': company_name,
                        'old_sic': current_sic,
                        'new_sic': new_sic,
                        'old_accuracy': old_accuracy,
                        'new_accuracy': new_accuracy,
                        'message': f'SIC code updated for {company_name}',
                        'workflow_steps': workflow_steps
                    })
                else:
                    return jsonify({'error': 'Failed to save SIC update'}), 500
            else:
                return jsonify({'error': 'SIC matcher not available'}), 500
                
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/update_main_table', methods=['POST'])
    def update_main_table():
        """API to update main table with new SIC data based on company matching"""
        try:
            data = request.get_json()
            
            # Extract company information from request
            company_name = data.get('company_name', '')
            company_registration = data.get('company_registration', '')
            old_sic = data.get('old_sic', '')
            new_sic = data.get('new_sic', '')
            new_accuracy = data.get('new_accuracy', 0.0)
            
            if app.company_data is None or app.company_data.empty:
                return jsonify({'error': 'No company data available'}), 400
            
            # Smart company matching strategy
            match_found = False
            matched_indices = []
            matching_strategy = ""
            
            # Strategy 1: Exact company name match
            if company_name:
                name_matches = app.company_data[app.company_data['Company Name'].str.strip().str.upper() == company_name.strip().upper()]
                if not name_matches.empty:
                    matched_indices = name_matches.index.tolist()
                    matching_strategy = f"Exact name match: '{company_name}'"
                    match_found = True
            
            # Strategy 2: Registration number match (if no name match found)
            if not match_found and company_registration and company_registration != 'nan':
                # Try both with and without leading zeros
                reg_variations = [
                    company_registration,
                    company_registration.lstrip('0'),
                    company_registration.zfill(8)  # Pad with zeros to 8 digits
                ]
                
                for reg_variant in reg_variations:
                    reg_matches = app.company_data[app.company_data['Registration number'].astype(str).str.strip() == reg_variant]
                    if not reg_matches.empty:
                        matched_indices = reg_matches.index.tolist()
                        matching_strategy = f"Registration match: '{reg_variant}'"
                        match_found = True
                        break
            
            # Strategy 3: Fuzzy company name match (if no exact matches)
            if not match_found and company_name:
                # Try partial name matching
                name_parts = company_name.upper().split()
                if name_parts:
                    main_name = name_parts[0]  # Take first significant word
                    fuzzy_matches = app.company_data[app.company_data['Company Name'].str.upper().str.contains(main_name, na=False)]
                    if not fuzzy_matches.empty:
                        matched_indices = fuzzy_matches.index.tolist()
                        matching_strategy = f"Fuzzy name match: '{main_name}'"
                        match_found = True
            
            # Strategy 4: SIC code + partial name match (last resort)
            if not match_found and old_sic and company_name:
                sic_name_matches = app.company_data[
                    (app.company_data['UK SIC 2007 Code'].astype(str) == str(old_sic)) &
                    (app.company_data['Company Name'].str.upper().str.contains(company_name.split()[0].upper(), na=False))
                ]
                if not sic_name_matches.empty:
                    matched_indices = sic_name_matches.index.tolist()
                    matching_strategy = f"SIC + name match: SIC {old_sic} + '{company_name.split()[0]}'"
                    match_found = True
            
            if not match_found:
                return jsonify({
                    'error': 'No matching company found',
                    'search_criteria': {
                        'company_name': company_name,
                        'company_registration': company_registration,
                        'old_sic': old_sic
                    }
                }), 404
            
            # Update all matched records
            updated_count = 0
            for idx in matched_indices:
                app.company_data.at[idx, 'New_SIC'] = new_sic
                app.company_data.at[idx, 'New_Accuracy'] = new_accuracy
                updated_count += 1
            
            # Get details of updated companies for response
            updated_companies = []
            for idx in matched_indices:
                row = app.company_data.iloc[idx]
                updated_companies.append({
                    'company_name': row['Company Name'],
                    'registration_number': str(row.get('Registration number', '')),
                    'old_sic': str(row.get('UK SIC 2007 Code', '')),
                    'new_sic': new_sic,
                    'new_accuracy': new_accuracy
                })
            
            return jsonify({
                'success': True,
                'message': f'Updated {updated_count} records in main table',
                'matching_strategy': matching_strategy,
                'updated_companies': updated_companies,
                'total_matched': len(matched_indices)
            })
            
        except Exception as e:
            return jsonify({'error': f'Update main table error: {str(e)}'}), 500

    @app.route('/api/run_agent_workflow', methods=['POST'])
    def run_agent_workflow():
        """Run the complete multi-agent workflow for real processing"""
        try:
            # Get input parameters
            data = request.get_json() or {}
            company_numbers = data.get('company_numbers', [])
            search_queries = data.get('search_queries', [])
            include_filing_history = data.get('include_filing_history', False)
            
            # If no specific companies provided, process a sample from loaded data
            if not company_numbers and not search_queries:
                if app.company_data is not None and not app.company_data.empty:
                    # Process first 10 companies as a sample
                    sample_companies = app.company_data.head(10).to_dict('records')
                    company_numbers = [comp.get('Registration number', f'sample_{i}') for i, comp in enumerate(sample_companies)]
                else:
                    return jsonify({'error': 'No company data available'}), 400
            
            # Prepare input for orchestrator
            workflow_input = {
                'company_numbers': company_numbers,
                'search_queries': search_queries, 
                'include_filing_history': include_filing_history
            }
            
            logger.info(f"Starting real agent workflow with input: {workflow_input}")
            
            # Run the complete workflow using the orchestrator
            workflow_results = app.orchestrator.run_complete_workflow(workflow_input)
            
            # Extract key information for UI display
            workflow_info = workflow_results.get('workflow_info', {})
            data_summary = workflow_results.get('data_summary', {})
            suggestions = workflow_results.get('suggestions', {})
            
            logger.info(f"Agent workflow completed. Status: {workflow_info.get('status')}")
            
            return jsonify({
                'success': True,
                'workflow_info': workflow_info,
                'data_summary': data_summary,
                'suggestions': suggestions,
                'companies_processed': data_summary.get('companies_processed', 0),
                'anomalies_detected': data_summary.get('anomalies_detected', 0),
                'suggestions_generated': data_summary.get('suggestions_generated', 0),
                'sector_suggestions': len(suggestions.get('sector_classifications', [])),
                'turnover_suggestions': len(suggestions.get('turnover_estimations', [])),
                'raw_results': workflow_results  # Full results for debugging
            })
            
        except Exception as e:
            error_msg = f"Agent workflow failed: {str(e)}"
            logger.error(error_msg)
            return jsonify({'error': error_msg}), 500

    @app.route('/api/predict_sic_real', methods=['POST'])
    @validate_api_input(validate_predict_sic_input) 
    def predict_sic_real(validated_data):
        """Use real SectorClassificationAgent for SIC prediction"""
        try:
            company_index = validated_data['company_index']
                
            # Ensure data is loaded
            if app.company_data is None:
                load_company_data()
                
            # Get company data
            if isinstance(app.company_data, pd.DataFrame):
                if company_index >= len(app.company_data):
                    return jsonify({'error': 'Invalid company index'}), 400
                company = app.company_data.iloc[company_index].to_dict()
            else:
                if not app.company_data or company_index >= len(app.company_data):
                    return jsonify({'error': 'Invalid company index'}), 400
                company = app.company_data[company_index]
                
            company_name = company.get('Company Name', 'Unknown')
            business_description = company.get('Business Description', '')
            current_sic = company.get('SIC Code (SIC 2007)', '')
            
            logger.info(f"Real SIC prediction for {company_name}: {business_description}")
            
            # Prepare data for sector classification agent
            company_data = {
                'company_number': company.get('Registration number', ''),
                'company_name': company_name,
                'description': business_description,
                'primary_sic_code': current_sic
            }
            
            # Use real sector classification agent
            agent_result = app.sector_agent.process([company_data])
            
            if agent_result.success and agent_result.data.get('suggestions'):
                suggestion = agent_result.data['suggestions'][0]
                
                predicted_sic = suggestion.suggested_sic_code
                confidence = suggestion.confidence
                reasoning = suggestion.reasoning
                keywords_matched = suggestion.keywords_matched
                
                # Calculate new accuracy using enhanced SIC matcher
                if hasattr(app, 'sic_matcher'):
                    # Use the predicted SIC confidence as new accuracy
                    new_accuracy = confidence * 100
                    
                    # Optionally validate the prediction using old accuracy calculation
                    validation_result = app.sic_matcher.calculate_old_accuracy(
                        business_description, predicted_sic
                    )
                    validation_score = validation_result.get('old_accuracy', new_accuracy)
                    
                    # Use the validation score if it's higher (more conservative)
                    new_accuracy = max(new_accuracy, validation_score)
                else:
                    new_accuracy = confidence * 100
                
                # Update company data with real prediction
                if isinstance(app.company_data, pd.DataFrame):
                    app.company_data.loc[company_index, 'Predicted_SIC'] = predicted_sic
                    app.company_data.loc[company_index, 'SIC_Confidence'] = confidence
                    app.company_data.loc[company_index, 'New_Accuracy'] = new_accuracy
                else:
                    app.company_data[company_index]['Predicted_SIC'] = predicted_sic
                    app.company_data[company_index]['SIC_Confidence'] = confidence
                    app.company_data[company_index]['New_Accuracy'] = new_accuracy
                
                # Create real workflow steps
                workflow_steps = [
                    {
                        "step": 1,
                        "agent": "Data Ingestion Agent",
                        "message": f"Loaded company data: {company_name}",
                        "status": "completed"
                    },
                    {
                        "step": 2,
                        "agent": "Sector Classification Agent", 
                        "message": f"Analyzing business description: {business_description[:50]}...",
                        "status": "completed"
                    },
                    {
                        "step": 3,
                        "agent": "Enhanced SIC Matcher",
                        "message": f"Predicted SIC: {predicted_sic} with {confidence:.1%} confidence",
                        "status": "completed"
                    },
                    {
                        "step": 4,
                        "agent": "Results Compilation Agent",
                        "message": f"New accuracy calculated: {new_accuracy:.1f}%",
                        "status": "completed"
                    }
                ]
                
                logger.info(f"Real SIC prediction completed: {predicted_sic} ({confidence:.1%})")
                
                return jsonify({
                    'success': True,
                    'company_name': company_name,
                    'current_sic': current_sic,
                    'predicted_sic': predicted_sic,
                    'confidence': f"{confidence:.1%}",
                    'new_accuracy': f"{new_accuracy:.1f}%",
                    'reasoning': reasoning,
                    'keywords_matched': keywords_matched,
                    'message': f'Real SIC prediction for {company_name}',
                    'workflow_steps': workflow_steps,
                    'agent_used': 'SectorClassificationAgent'
                })
            else:
                return jsonify({'error': 'SIC prediction failed: No suitable match found'}), 500
                
        except Exception as e:
            error_msg = f"Real SIC prediction failed: {str(e)}"
            logger.error(error_msg)
            return jsonify({'error': error_msg}), 500

    @app.route('/api/test_agents', methods=['GET'])
    def test_agent_integration():
        """Test route to verify agent integration is working"""
        try:
            # Test orchestrator
            orchestrator_status = "‚úÖ Available" if hasattr(app, 'orchestrator') else "‚ùå Not available"
            
            # Test sector agent
            sector_agent_status = "‚úÖ Available" if hasattr(app, 'sector_agent') else "‚ùå Not available"
            
            # Test SIC matcher
            sic_matcher_status = "‚úÖ Available" if hasattr(app, 'sic_matcher') else "‚ùå Not available"
            
            # Test with sample data
            test_result = None
            if hasattr(app, 'sector_agent'):
                try:
                    sample_company = {
                        'company_number': 'TEST001',
                        'company_name': 'Test Catering Company',
                        'description': 'Food catering and event services',
                        'primary_sic_code': '56210'
                    }
                    
                    agent_result = app.sector_agent.process([sample_company])
                    if agent_result.success:
                        test_result = "‚úÖ Sector agent working - Sample prediction successful"
                    else:
                        test_result = f"‚ö†Ô∏è Sector agent failed: {agent_result.error_message}"
                except Exception as e:
                    test_result = f"‚ùå Sector agent test failed: {str(e)}"
            
            return jsonify({
                'agent_integration_status': {
                    'orchestrator': orchestrator_status,
                    'sector_agent': sector_agent_status,
                    'sic_matcher': sic_matcher_status,
                    'test_result': test_result
                },
                'available_routes': [
                    '/api/run_agent_workflow - Full multi-agent workflow',
                    '/api/predict_sic_real - Real SIC prediction using agents',
                    '/api/predict_sic - Enhanced with real agent option (use_real_agents: true)'
                ],
                'usage_instructions': {
                    'real_sic_prediction': 'POST to /api/predict_sic with {"company_index": 0, "use_real_agents": true}',
                    'full_workflow': 'POST to /api/run_agent_workflow with optional company_numbers array'
                }
            })
            
        except Exception as e:
            return jsonify({'error': f'Agent test failed: {str(e)}'}), 500
    
    @app.route('/api/company_details/<int:company_index>', methods=['GET'])
    def get_company_details_with_reasoning(company_index):
        """
        Get comprehensive company details with AI reasoning for SIC accuracy.
        This endpoint provides all company data plus AI-generated explanations.
        """
        logger.info(f"üè¢ Company details requested for index: {company_index}")
        
        try:
            # Validate company index
            if company_index < 0 or company_index >= len(app.company_data):
                return jsonify({
                    'error': f'Invalid company index: {company_index}. Valid range: 0-{len(app.company_data)-1}'
                }), 400
            
            # Get company data
            company = app.company_data.iloc[company_index].to_dict()
            
            # Helper function to safely convert values and handle NaN
            def safe_convert(value, default='N/A'):
                """Safely convert values, handling NaN and None"""
                import math
                if value is None:
                    return default
                if isinstance(value, (int, float)) and math.isnan(value):
                    return default
                if isinstance(value, str) and value.lower() in ['nan', 'none', '']:
                    return default
                return value
            
            # Helper function for numeric values
            def safe_numeric(value, default=0):
                """Safely convert numeric values, handling NaN"""
                import math
                try:
                    if value is None:
                        return default
                    if isinstance(value, (int, float)):
                        if math.isnan(value):
                            return default
                        return float(value)
                    if isinstance(value, str):
                        if value.lower() in ['nan', 'none', '', 'n/a']:
                            return default
                        return float(value)
                    return default
                except (ValueError, TypeError):
                    return default
            
            # Prepare data for AI reasoning agent
            reasoning_data = {
                'company_name': safe_convert(company.get('Company Name', ''), 'Unknown Company'),
                'company_description': safe_convert(company.get('Business Description', ''), ''),
                'current_sic': str(safe_convert(company.get('UK SIC 2007 Code', ''), '')),
                'old_accuracy': safe_numeric(company.get('Old_Accuracy', 0), 0),
                'new_accuracy': safe_numeric(company.get('New_Accuracy')) if company.get('New_Accuracy') is not None else None,
                'sic_description': safe_convert(company.get('UK SIC 2007 Description', ''), '')
            }
            
            # Get AI reasoning (import here to avoid circular imports)
            try:
                from app.agents.ai_reasoning_agent import ai_reasoning_agent
                reasoning_result = ai_reasoning_agent.process(reasoning_data)
                
                if reasoning_result.success:
                    ai_reasoning = reasoning_result.data.get('reasoning', 'No reasoning available')
                    logger.info(f"‚úÖ AI reasoning generated for {company.get('Company_Name', 'Unknown')}")
                else:
                    ai_reasoning = f"AI reasoning unavailable: {reasoning_result.error_message}"
                    logger.warning(f"‚ö†Ô∏è AI reasoning failed for company {company_index}")
                    
            except Exception as ai_error:
                logger.error(f"‚ùå AI reasoning agent error: {str(ai_error)}")
                ai_reasoning = f"AI reasoning temporarily unavailable. Please check OpenAI API configuration."
            
            # Compile comprehensive response
            response_data = {
                'company_index': company_index,
                'company_data': {
                    'Company_Name': safe_convert(company.get('Company Name', 'N/A')),
                    'Registration_Number': safe_convert(company.get('Registration number', 'N/A')),
                    'UK_SIC_2007_Code': safe_convert(company.get('UK SIC 2007 Code', 'N/A')),
                    'UK_SIC_2007_Description': safe_convert(company.get('UK SIC 2007 Description', 'N/A')),
                    'Old_Accuracy': safe_numeric(company.get('Old_Accuracy'), 0),
                    'New_Accuracy': safe_numeric(company.get('New_Accuracy')) if company.get('New_Accuracy') is not None else None,
                    'Business_Description': safe_convert(company.get('Business Description', 'No description available')),
                    'Sales_USD': safe_convert(company.get('Sales (USD)', 'N/A')),
                    'Employees_Total': safe_convert(company.get('Employees (Total)', 'N/A')),
                    'Address_Line_1': safe_convert(company.get('Address Line 1', 'N/A')),
                    'City': safe_convert(company.get('City', 'N/A')),
                    'Post_Code': safe_convert(company.get('Post Code', 'N/A')),
                    'Country': safe_convert(company.get('Country', 'N/A')),
                    'Website': safe_convert(company.get('Website', 'N/A')),
                    'Phone': safe_convert(company.get('Phone', 'N/A'))
                },
                'ai_reasoning': ai_reasoning,
                'analysis_metadata': {
                    'generated_at': datetime.now().isoformat(),
                    'reasoning_source': 'ai_reasoning_agent',
                    'accuracy_improvement': (
                        safe_numeric(company.get('New_Accuracy'), 0) - safe_numeric(company.get('Old_Accuracy'), 0)
                    ) if company.get('New_Accuracy') is not None else 0
                }
            }
            
            logger.info(f"‚úÖ Company details with AI reasoning returned for index {company_index}")
            return jsonify(response_data)
            
        except Exception as e:
            logger.error(f"‚ùå Error getting company details: {str(e)}")
            return jsonify({
                'error': f'Failed to get company details: {str(e)}',
                'company_index': company_index
            }), 500

    # Load data when app starts
    load_company_data()
    
    return app

if __name__ == '__main__':
    app = create_app()
    
    # This code should only run when flask_main.py is executed directly
    # When imported by main.py, main.py handles the app.run()
    if __name__ == '__main__':
        # Use dynamic port configuration like all other files
        import os
        port = int(os.environ.get('PORT', os.environ.get('WEBSITES_PORT', 8000)))
        
        logger.info(f"Starting Enhanced Flask App on http://0.0.0.0:{port}")
        app.run(host='0.0.0.0', port=port, debug=True)